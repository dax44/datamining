<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>5 Pochodne drzew decyzyjnych | Eksploracja danych</title>
  <meta name="description" content="Książka stanowi materiał źródłowy do przeprowadzenia przedmiotu Eksploracja Danych.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="5 Pochodne drzew decyzyjnych | Eksploracja danych" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://dax44.github.io/datamining/" />
  
  <meta property="og:description" content="Książka stanowi materiał źródłowy do przeprowadzenia przedmiotu Eksploracja Danych." />
  <meta name="github-repo" content="dax44/datamining" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5 Pochodne drzew decyzyjnych | Eksploracja danych" />
  
  <meta name="twitter:description" content="Książka stanowi materiał źródłowy do przeprowadzenia przedmiotu Eksploracja Danych." />
  



<meta name="date" content="2019-05-06">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="drzewa-decyzyjne.html">
<link rel="next" href="klasyfikatory-liniowe.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
    Macros: {
        P: '{\\mathrm{P}}',
        E: '{\\mathrm{E}}',
        Var: '{\\mathrm{Var}}',
        Cor: '{\\mathrm{Cor}}',
        Cov: '{\\mathrm{Cov}}',
        Tr: '{\\mathrm{Tr}}',
        probit: '{\\mathrm{probit}}',
        logit: '{\\mathrm{logit}}'
    },
}
});
</script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Eksploracja Danych</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Wstęp</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#o-ksiazce"><i class="fa fa-check"></i>O książce</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#zakres-przedmiotu"><i class="fa fa-check"></i>Zakres przedmiotu</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#zakres-technik-stosowanych-w-data-mining"><i class="fa fa-check"></i>Zakres technik stosowanych w data mining</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#etapy-eksploracji-danych"><i class="fa fa-check"></i>Etapy eksploracji danych</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="roz1.html"><a href="roz1.html"><i class="fa fa-check"></i><b>1</b> Import danych</a></li>
<li class="chapter" data-level="2" data-path="przygotowanie-danych.html"><a href="przygotowanie-danych.html"><i class="fa fa-check"></i><b>2</b> Przygotowanie danych</a><ul>
<li class="chapter" data-level="2.1" data-path="przygotowanie-danych.html"><a href="przygotowanie-danych.html#identyfikacja-brakow-danych"><i class="fa fa-check"></i><b>2.1</b> Identyfikacja braków danych</a></li>
<li class="chapter" data-level="2.2" data-path="przygotowanie-danych.html"><a href="przygotowanie-danych.html#zastepowanie-brakow-danych"><i class="fa fa-check"></i><b>2.2</b> Zastępowanie braków danych</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="podzia-metod-data-mining.html"><a href="podzia-metod-data-mining.html"><i class="fa fa-check"></i><b>3</b> Podział metod data mining</a><ul>
<li class="chapter" data-level="3.1" data-path="podzia-metod-data-mining.html"><a href="podzia-metod-data-mining.html#rodzaje-wnioskowania"><i class="fa fa-check"></i><b>3.1</b> Rodzaje wnioskowania</a><ul>
<li class="chapter" data-level="3.1.1" data-path="podzia-metod-data-mining.html"><a href="podzia-metod-data-mining.html#dziedzina"><i class="fa fa-check"></i><b>3.1.1</b> Dziedzina</a></li>
<li class="chapter" data-level="3.1.2" data-path="podzia-metod-data-mining.html"><a href="podzia-metod-data-mining.html#obserwacja"><i class="fa fa-check"></i><b>3.1.2</b> Obserwacja</a></li>
<li class="chapter" data-level="3.1.3" data-path="podzia-metod-data-mining.html"><a href="podzia-metod-data-mining.html#atrybuty-obserwacji"><i class="fa fa-check"></i><b>3.1.3</b> Atrybuty obserwacji</a></li>
<li class="chapter" data-level="3.1.4" data-path="podzia-metod-data-mining.html"><a href="podzia-metod-data-mining.html#zbior-uczacy"><i class="fa fa-check"></i><b>3.1.4</b> Zbiór uczący</a></li>
<li class="chapter" data-level="3.1.5" data-path="podzia-metod-data-mining.html"><a href="podzia-metod-data-mining.html#zbior-testowy"><i class="fa fa-check"></i><b>3.1.5</b> Zbiór testowy</a></li>
<li class="chapter" data-level="3.1.6" data-path="podzia-metod-data-mining.html"><a href="podzia-metod-data-mining.html#model"><i class="fa fa-check"></i><b>3.1.6</b> Model</a></li>
<li class="chapter" data-level="3.1.7" data-path="podzia-metod-data-mining.html"><a href="podzia-metod-data-mining.html#jakosc-dopasowania-modelu"><i class="fa fa-check"></i><b>3.1.7</b> Jakość dopasowania modelu</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="podzia-metod-data-mining.html"><a href="podzia-metod-data-mining.html#modele-regresyjne"><i class="fa fa-check"></i><b>3.2</b> Modele regresyjne</a></li>
<li class="chapter" data-level="3.3" data-path="podzia-metod-data-mining.html"><a href="podzia-metod-data-mining.html#modele-klasyfikacyjne"><i class="fa fa-check"></i><b>3.3</b> Modele klasyfikacyjne</a></li>
<li class="chapter" data-level="3.4" data-path="podzia-metod-data-mining.html"><a href="podzia-metod-data-mining.html#modele-grupujace"><i class="fa fa-check"></i><b>3.4</b> Modele grupujące</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="drzewa-decyzyjne.html"><a href="drzewa-decyzyjne.html"><i class="fa fa-check"></i><b>4</b> Drzewa decyzyjne</a><ul>
<li class="chapter" data-level="4.1" data-path="drzewa-decyzyjne.html"><a href="drzewa-decyzyjne.html#wezy-i-gaezie"><i class="fa fa-check"></i><b>4.1</b> Węzły i gałęzie</a></li>
<li class="chapter" data-level="4.2" data-path="drzewa-decyzyjne.html"><a href="drzewa-decyzyjne.html#rodzaje-regu-podziau"><i class="fa fa-check"></i><b>4.2</b> Rodzaje reguł podziału</a><ul>
<li class="chapter" data-level="4.2.1" data-path="drzewa-decyzyjne.html"><a href="drzewa-decyzyjne.html#podziay-dla-atrybutow-ze-skali-nominalnej"><i class="fa fa-check"></i><b>4.2.1</b> Podziały dla atrybutów ze skali nominalnej</a></li>
<li class="chapter" data-level="4.2.2" data-path="drzewa-decyzyjne.html"><a href="drzewa-decyzyjne.html#podziay-dla-atrybutow-ze-skali-ciagej"><i class="fa fa-check"></i><b>4.2.2</b> Podziały dla atrybutów ze skali ciągłej</a></li>
<li class="chapter" data-level="4.2.3" data-path="drzewa-decyzyjne.html"><a href="drzewa-decyzyjne.html#podziay-dla-atrybutow-ze-skali-porzadkowej"><i class="fa fa-check"></i><b>4.2.3</b> Podziały dla atrybutów ze skali porządkowej</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="drzewa-decyzyjne.html"><a href="drzewa-decyzyjne.html#algorytm-budowy-drzewa"><i class="fa fa-check"></i><b>4.3</b> Algorytm budowy drzewa</a></li>
<li class="chapter" data-level="4.4" data-path="drzewa-decyzyjne.html"><a href="drzewa-decyzyjne.html#kryteria-zatrzymania"><i class="fa fa-check"></i><b>4.4</b> Kryteria zatrzymania</a></li>
<li class="chapter" data-level="4.5" data-path="drzewa-decyzyjne.html"><a href="drzewa-decyzyjne.html#reguy-podziau"><i class="fa fa-check"></i><b>4.5</b> Reguły podziału</a></li>
<li class="chapter" data-level="4.6" data-path="drzewa-decyzyjne.html"><a href="drzewa-decyzyjne.html#przycinanie-drzewa-decyzyjnego"><i class="fa fa-check"></i><b>4.6</b> Przycinanie drzewa decyzyjnego</a><ul>
<li class="chapter" data-level="4.6.1" data-path="drzewa-decyzyjne.html"><a href="drzewa-decyzyjne.html#przycinanie-redukujace-bad"><i class="fa fa-check"></i><b>4.6.1</b> Przycinanie redukujące błąd</a></li>
<li class="chapter" data-level="4.6.2" data-path="drzewa-decyzyjne.html"><a href="drzewa-decyzyjne.html#przycinanie-minimalizujace-bad"><i class="fa fa-check"></i><b>4.6.2</b> Przycinanie minimalizujące błąd</a></li>
<li class="chapter" data-level="4.6.3" data-path="drzewa-decyzyjne.html"><a href="drzewa-decyzyjne.html#przycinanie-ze-wzgledu-na-wspoczynnik-zozonosci-drzewa"><i class="fa fa-check"></i><b>4.6.3</b> Przycinanie ze względu na współczynnik złożoności drzewa</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="drzewa-decyzyjne.html"><a href="drzewa-decyzyjne.html#obsuga-brakow-danych"><i class="fa fa-check"></i><b>4.7</b> Obsługa braków danych</a></li>
<li class="chapter" data-level="4.8" data-path="drzewa-decyzyjne.html"><a href="drzewa-decyzyjne.html#zalety-i-wady"><i class="fa fa-check"></i><b>4.8</b> Zalety i wady</a><ul>
<li class="chapter" data-level="4.8.1" data-path="drzewa-decyzyjne.html"><a href="drzewa-decyzyjne.html#zalety"><i class="fa fa-check"></i><b>4.8.1</b> Zalety</a></li>
<li class="chapter" data-level="4.8.2" data-path="drzewa-decyzyjne.html"><a href="drzewa-decyzyjne.html#wady"><i class="fa fa-check"></i><b>4.8.2</b> Wady</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="drzewa-decyzyjne.html"><a href="drzewa-decyzyjne.html#inne-algorytmy-budowy-drzew-decyzyjnych-implementowane-w-r"><i class="fa fa-check"></i><b>4.9</b> Inne algorytmy budowy drzew decyzyjnych implementowane w <strong>R</strong></a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="pochodne-drzew-decyzyjnych.html"><a href="pochodne-drzew-decyzyjnych.html"><i class="fa fa-check"></i><b>5</b> Pochodne drzew decyzyjnych</a><ul>
<li class="chapter" data-level="5.1" data-path="pochodne-drzew-decyzyjnych.html"><a href="pochodne-drzew-decyzyjnych.html#bagging"><i class="fa fa-check"></i><b>5.1</b> Bagging</a></li>
<li class="chapter" data-level="5.2" data-path="pochodne-drzew-decyzyjnych.html"><a href="pochodne-drzew-decyzyjnych.html#lasy-losowe"><i class="fa fa-check"></i><b>5.2</b> Lasy losowe</a></li>
<li class="chapter" data-level="5.3" data-path="pochodne-drzew-decyzyjnych.html"><a href="pochodne-drzew-decyzyjnych.html#boosting"><i class="fa fa-check"></i><b>5.3</b> Boosting</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="klasyfikatory-liniowe.html"><a href="klasyfikatory-liniowe.html"><i class="fa fa-check"></i><b>6</b> Klasyfikatory liniowe</a><ul>
<li class="chapter" data-level="6.1" data-path="klasyfikatory-liniowe.html"><a href="klasyfikatory-liniowe.html#reprezentacja-progowa"><i class="fa fa-check"></i><b>6.1</b> Reprezentacja progowa</a></li>
<li class="chapter" data-level="6.2" data-path="klasyfikatory-liniowe.html"><a href="klasyfikatory-liniowe.html#reprezentacja-logitowa"><i class="fa fa-check"></i><b>6.2</b> Reprezentacja logitowa</a></li>
<li class="chapter" data-level="6.3" data-path="klasyfikatory-liniowe.html"><a href="klasyfikatory-liniowe.html#wady-klasyfikatorow-liniowych"><i class="fa fa-check"></i><b>6.3</b> Wady klasyfikatorów liniowych</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="regresja-logistyczna.html"><a href="regresja-logistyczna.html"><i class="fa fa-check"></i><b>7</b> Regresja logistyczna</a><ul>
<li class="chapter" data-level="7.1" data-path="regresja-logistyczna.html"><a href="regresja-logistyczna.html#model-1"><i class="fa fa-check"></i><b>7.1</b> Model</a></li>
<li class="chapter" data-level="7.2" data-path="regresja-logistyczna.html"><a href="regresja-logistyczna.html#estymacja-parametrow-modelu"><i class="fa fa-check"></i><b>7.2</b> Estymacja parametrów modelu</a></li>
<li class="chapter" data-level="7.3" data-path="regresja-logistyczna.html"><a href="regresja-logistyczna.html#interpretacja"><i class="fa fa-check"></i><b>7.3</b> Interpretacja</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="LDA.html"><a href="LDA.html"><i class="fa fa-check"></i><b>8</b> Analiza dyskryminacyjna</a><ul>
<li class="chapter" data-level="8.1" data-path="LDA.html"><a href="LDA.html#liniowa-analiza-dyskryminacyjna-fishera"><i class="fa fa-check"></i><b>8.1</b> Liniowa analiza dyskryminacyjna Fisher’a</a><ul>
<li class="chapter" data-level="8.1.1" data-path="LDA.html"><a href="LDA.html#dwie-kategorie-zmiennej-grupujacej"><i class="fa fa-check"></i><b>8.1.1</b> Dwie kategorie zmiennej grupującej</a></li>
<li class="chapter" data-level="8.1.2" data-path="LDA.html"><a href="LDA.html#k-kategorii-zmiennej-grupujacej"><i class="fa fa-check"></i><b>8.1.2</b> <span class="math inline">\(k\)</span>-kategorii zmiennej grupującej</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="LDA.html"><a href="LDA.html#liniowa-analiza-dyskryminacyjna---podejscie-probabilistyczne"><i class="fa fa-check"></i><b>8.2</b> Liniowa analiza dyskryminacyjna - podejście probabilistyczne</a><ul>
<li class="chapter" data-level="8.2.1" data-path="LDA.html"><a href="LDA.html#przypI"><i class="fa fa-check"></i><b>8.2.1</b> Przypadek gdy <span class="math inline">\(\boldsymbol{\Sigma}_i=\sigma^2I\)</span></a></li>
<li class="chapter" data-level="8.2.2" data-path="LDA.html"><a href="LDA.html#przypSig"><i class="fa fa-check"></i><b>8.2.2</b> Przypadek gdy <span class="math inline">\(\boldsymbol \Sigma_i=\boldsymbol \Sigma\)</span></a></li>
<li class="chapter" data-level="8.2.3" data-path="LDA.html"><a href="LDA.html#przypadek-gdy-boldsymbol-sigma_i-jest-dowolnej-postaci"><i class="fa fa-check"></i><b>8.2.3</b> Przypadek gdy <span class="math inline">\(\boldsymbol \Sigma_i\)</span> jest dowolnej postaci</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="LDA.html"><a href="LDA.html#analiza-dyskryminacyjna-metoda-czesciowych-najmniejszych-kwadratow"><i class="fa fa-check"></i><b>8.3</b> Analiza dyskryminacyjna metodą częściowych najmniejszych kwadratów</a></li>
<li class="chapter" data-level="8.4" data-path="LDA.html"><a href="LDA.html#regularyzowana-analiza-dyskryminacyjna"><i class="fa fa-check"></i><b>8.4</b> Regularyzowana analiza dyskryminacyjna</a></li>
<li class="chapter" data-level="8.5" data-path="LDA.html"><a href="LDA.html#analiza-dyskryminacyjna-mieszana"><i class="fa fa-check"></i><b>8.5</b> Analiza dyskryminacyjna mieszana</a></li>
<li class="chapter" data-level="8.6" data-path="LDA.html"><a href="LDA.html#elastyczna-analiza-dyskryminacyjna"><i class="fa fa-check"></i><b>8.6</b> Elastyczna analiza dyskryminacyjna</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="bayes.html"><a href="bayes.html"><i class="fa fa-check"></i><b>9</b> Klasyfikatory bayesowskie</a><ul>
<li class="chapter" data-level="9.1" data-path="bayes.html"><a href="bayes.html#klasyfikator-maximum-a-posteriori-map"><i class="fa fa-check"></i><b>9.1</b> Klasyfikator maximum a posteriori (MAP)</a></li>
<li class="chapter" data-level="9.2" data-path="bayes.html"><a href="bayes.html#klasyfikator-najwiekszej-wiarogodnosci-ml"><i class="fa fa-check"></i><b>9.2</b> Klasyfikator największej wiarogodności (ML)</a></li>
<li class="chapter" data-level="9.3" data-path="bayes.html"><a href="bayes.html#naiwny-klasyfikator-bayesa-nb"><i class="fa fa-check"></i><b>9.3</b> Naiwny klasyfikator Bayesa (NB)</a></li>
<li class="chapter" data-level="9.4" data-path="bayes.html"><a href="bayes.html#zalety-i-wady-1"><i class="fa fa-check"></i><b>9.4</b> Zalety i wady</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="metoda-k-najblizszych-sasiadow.html"><a href="metoda-k-najblizszych-sasiadow.html"><i class="fa fa-check"></i><b>10</b> Metoda <span class="math inline">\(k\)</span> najbliższych sąsiadów</a></li>
<li class="chapter" data-level="11" data-path="uogolnione-modele-addytywne.html"><a href="uogolnione-modele-addytywne.html"><i class="fa fa-check"></i><b>11</b> Uogólnione modele addytywne</a><ul>
<li class="chapter" data-level="11.1" data-path="uogolnione-modele-addytywne.html"><a href="uogolnione-modele-addytywne.html#przypadek-jednowymiarowy"><i class="fa fa-check"></i><b>11.1</b> Przypadek jednowymiarowy</a></li>
<li class="chapter" data-level="11.2" data-path="uogolnione-modele-addytywne.html"><a href="uogolnione-modele-addytywne.html#przypadek-wielowymiarowy"><i class="fa fa-check"></i><b>11.2</b> Przypadek wielowymiarowy</a></li>
<li class="chapter" data-level="11.3" data-path="uogolnione-modele-addytywne.html"><a href="uogolnione-modele-addytywne.html#uogolnione-modele-addytywne-1"><i class="fa fa-check"></i><b>11.3</b> Uogólnione modele addytywne</a><ul>
<li class="chapter" data-level="11.3.1" data-path="uogolnione-modele-addytywne.html"><a href="uogolnione-modele-addytywne.html#algorytm-uczenia-modelu-gam"><i class="fa fa-check"></i><b>11.3.1</b> Algorytm uczenia modelu GAM</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="metoda-wektorow-nosnych.html"><a href="metoda-wektorow-nosnych.html"><i class="fa fa-check"></i><b>12</b> Metoda wektorów nośnych</a><ul>
<li class="chapter" data-level="12.1" data-path="metoda-wektorow-nosnych.html"><a href="metoda-wektorow-nosnych.html#wprowadzenie"><i class="fa fa-check"></i><b>12.1</b> Wprowadzenie</a></li>
<li class="chapter" data-level="12.2" data-path="metoda-wektorow-nosnych.html"><a href="metoda-wektorow-nosnych.html#definicja-modelu-dla-klas-liniowo-separowalnych"><i class="fa fa-check"></i><b>12.2</b> Definicja modelu dla klas liniowo separowalnych</a></li>
<li class="chapter" data-level="12.3" data-path="metoda-wektorow-nosnych.html"><a href="metoda-wektorow-nosnych.html#definicja-modelu-dla-klas-nieliniowo-separowalnych"><i class="fa fa-check"></i><b>12.3</b> Definicja modelu dla klas nieliniowo separowalnych</a></li>
<li class="chapter" data-level="12.4" data-path="metoda-wektorow-nosnych.html"><a href="metoda-wektorow-nosnych.html#definicja-modelu-jadrowego"><i class="fa fa-check"></i><b>12.4</b> Definicja modelu jądrowego</a></li>
<li class="chapter" data-level="12.5" data-path="metoda-wektorow-nosnych.html"><a href="metoda-wektorow-nosnych.html#zalety-i-wady-2"><i class="fa fa-check"></i><b>12.5</b> Zalety i wady</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliografia.html"><a href="bibliografia.html"><i class="fa fa-check"></i>Bibliografia</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Eksploracja danych</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="pochodne-drzew-decyzyjnych" class="section level1">
<h1><span class="header-section-number">5</span> Pochodne drzew decyzyjnych</h1>
<p>Przykład zastosowania drzew decyzyjnych na zbiorze <code>iris</code> w poprzednich <a href="#przyk41">przykładach</a> może skłaniać do przypuszczenia, że drzewa decyzyjne zawsze dobrze radzą sobie z predykcją wartości wynikowej. Niestety w przykładach nieco bardziej skomplikowanych, gdzie chociażby klasy zmiennej wynikowej nie są tak wyraźnie separowalne, drzewa decyzyjne wypadają gorzej w porównaniu z innymi modelami nadzorowanego uczenia maszynowego.</p>
<p>I tak u podstaw metod bazujących na prostych drzewach decyzyjnych stał pomysł, że skoro jedno drzewo nie ma wystarczających własności predykcyjnych, to może zastosowanie wielu drzew połączonych w pewien sposób poprawi je. Tak powstały metody <em>bagging</em>, <em>random forest</em> i <em>boosting</em><a href="#fn17" class="footnote-ref" id="fnref17"><sup>17</sup></a>. Należy zaznaczyć, że metody znajdują swoje zastosowanie również w innych modelach nadzorowanego uczenia maszynowego.</p>
<div id="bagging" class="section level2">
<h2><span class="header-section-number">5.1</span> Bagging</h2>
<p>Technika ta została wprowadzona przez <span class="citation">Breiman (<a href="#ref-breiman1996">1996</a>)</span> i ma na celu zmniejszenie wariancji modelu pojedynczego drzewa. Podobnie jak technika <em>bootstrap</em>, w której statystyki są wyliczane na wielu próbach pobranych z tego samego rozkładu (próby), w metodzie bagging losuje się wiele prób ze zbioru uczącego (najczęściej poprzez wielokrotne losowanie próby o rozmiarze zbioru uczącego ze zwracaniem), a następnie dla każdej próby bootstrapowej buduje się drzewo. W ten sposób otrzymujemy <span class="math inline">\(B\)</span> drzew decyzyjnych <span class="math inline">\(\hat{f}^1(x), \hat{f}^2(x),\ldots, \hat{f}^B(x)\)</span>. Na koniec poprzez uśrednienie otrzymujemy model charakteryzujący się większą precyzją
<span class="math display">\[\begin{equation}
    \hat{f}_{bag}(x)=\frac1B\sum_{b=1}^B\hat{f}^b(x).
\end{equation}\]</span></p>
<p>Ponieważ podczas budowy drzew na podstawie prób bootstrapowych nie kontrolujemy złożoności, to w rezultacie każde z drzew może charakteryzować się dużą wariancją. Poprzez uśrednianie wyników pojedynczych drzew otrzymujemy mniejsze obciążenie ale również przy dostatecznie dużej liczbie prób (<span class="math inline">\(B\)</span> często liczy się w setkach, czy tysiącach) zmniejszamy wariancję “średniej” predykcji z drzew. Oczywiście metodę tą trzeba dostosować do zadań klasyfikacyjnych, ponieważ nie istnieje średnia klasyfikacji z wielu drzew. W miejsce średniej stosuje się modę, czyli wartość dominującą.</p>
<p>Przyjrzyjmy się jak maszyna losuje obserwacje ze zwracaniem</p>
<pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="ot">NULL</span>
m &lt;-<span class="st"> </span><span class="ot">NULL</span>
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>){
    x &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">500</span>, <span class="dt">size =</span> <span class="dv">500</span>, <span class="dt">replace =</span> T)
    y &lt;-<span class="st"> </span><span class="kw">setdiff</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">500</span>, x)
    z &lt;-<span class="st"> </span><span class="kw">unique</span>(x)
    n[i] &lt;-<span class="st"> </span><span class="kw">length</span>(z)
    m[i] &lt;-<span class="st"> </span><span class="kw">length</span>(y)
}
<span class="kw">mean</span>(n)<span class="op">/</span><span class="dv">500</span><span class="op">*</span><span class="dv">100</span></code></pre>
<pre><code>## [1] 63.2802</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(m)<span class="op">/</span><span class="dv">500</span><span class="op">*</span><span class="dv">100</span></code></pre>
<pre><code>## [1] 36.7198</code></pre>
<p>Faktycznie uczenie modelu metodą bagging odbywa się średnio na 2/3 obserwacji zbioru uczącego wylosowanych do prób bootstrapowych, a pozostała 1/3 (ang. <em>out-of-bag</em>) jest wykorzystana do oceny jakości predykcji.</p>
<p>Niewątpliwą zaletą drzew decyzyjnych była ich łatwa interpretacja. W przypadku metody bagging jest ona znacznie utrudniona, ponieważ jej wynik składa się z agregacji wielu drzew. Można natomiast ocenić ważność predyktorów (ang. <em>variable importance</em>). I tak, przez obserwację spadku <span class="math inline">\(RSS\)</span> dla baggingu regresyjnego przy zastosowaniu danego predyktora w podziałach drzewa i uśrednieniu wyniku otrzymamy wskaźnik ważności predyktora dużo lepszy niż dla pojedynczego drzewa. W przypadku baggingu klasyfikacyjnego w miejsce <span class="math inline">\(RSS\)</span> stosujemy indeks Gini’ego.</p>
<p>Implementacja R-owa metody bagging znajduje się w pakiecie <strong>ipred</strong>, a funkcja do budowy modelu nazywa się <code>bagging</code> <span class="citation">(Peters and Hothorn <a href="#ref-R-ipred">2018</a>)</span>. Można również stosować funkcję <code>randomForest</code> pakietu <strong>randomForest</strong> <span class="citation">(Liaw and Wiener <a href="#ref-R-las">2002</a>)</span> - powody takiego działania wyjaśnią się w podrozdziale <a href="pochodne-drzew-decyzyjnych.html#lasy-losowe">Lasy losowe</a>.</p>

<div class="example">
<span id="exm:przyk51" class="example"><strong>Przykład 5.1  </strong></span>Tym razem cel zadania jest regresyjny i polega na ustaleniu miary tendencji centralnej ceny mieszkań w Bostonie na podstawie zmiennych umieszczonych w zbiorze <code>Boston</code> pakietu <strong>MASS</strong> <span class="citation">(Venables and Ripley <a href="#ref-R-MASS">2002</a>)</span>. Zmienną zależną będzie mediana cen mieszkań na przedmieściach Bostonu (<code>medv</code>).
</div>

<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(MASS)
<span class="kw">head</span>(Boston)</code></pre>
<pre><code>##      crim zn indus chas   nox    rm  age    dis rad tax ptratio  black
## 1 0.00632 18  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3 396.90
## 2 0.02731  0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8 396.90
## 3 0.02729  0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8 392.83
## 4 0.03237  0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7 394.63
## 5 0.06905  0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7 396.90
## 6 0.02985  0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7 394.12
##   lstat medv
## 1  4.98 24.0
## 2  9.14 21.6
## 3  4.03 34.7
## 4  2.94 33.4
## 5  5.33 36.2
## 6  5.21 28.7</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">2019</span>)
boston.train &lt;-<span class="st"> </span>Boston <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">sample_frac</span>(<span class="dt">size =</span> <span class="dv">2</span><span class="op">/</span><span class="dv">3</span>)
boston.test &lt;-<span class="st"> </span><span class="kw">setdiff</span>(Boston, boston.train)</code></pre>
<p>Aby móc porównać wyniki predykcji z metody bagging, najpierw zostanie zbudowane jedno drzewo decyzyjne w oparciu o algorytm CART.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rpart)
<span class="kw">library</span>(rpart.plot)
boston.rpart &lt;-<span class="st"> </span><span class="kw">rpart</span>(medv<span class="op">~</span>., <span class="dt">data =</span> boston.train)
x &lt;-<span class="st"> </span><span class="kw">summary</span>(boston.rpart)</code></pre>
<pre><code>## Call:
## rpart(formula = medv ~ ., data = boston.train)
##   n= 337 
## 
##           CP nsplit rel error    xerror       xstd
## 1 0.49839799      0 1.0000000 1.0086928 0.10259521
## 2 0.15725128      1 0.5016020 0.5442932 0.06125724
## 3 0.07485605      2 0.3443507 0.4031978 0.05139310
## 4 0.03672387      3 0.2694947 0.3127794 0.04599170
## 5 0.03552748      4 0.2327708 0.2974517 0.04560807
## 6 0.01695185      5 0.1972433 0.2553208 0.04022970
## 7 0.01422576      6 0.1802915 0.2713816 0.04099092
## 8 0.01103490      7 0.1660657 0.2744789 0.04107777
## 9 0.01000000      8 0.1550308 0.2720415 0.04119266
## 
## Variable importance
##      rm   lstat   indus ptratio    crim     age     nox     dis      zn 
##      33      19       9       8       7       6       6       5       3 
##     tax     rad    chas 
##       2       1       1 
## 
## Node number 1: 337 observations,    complexity param=0.498398
##   mean=22.69792, MSE=79.32964 
##   left son=2 (286 obs) right son=3 (51 obs)
##   Primary splits:
##       rm      &lt; 6.92     to the left,  improve=0.4983980, (0 missing)
##       lstat   &lt; 9.725    to the right, improve=0.4424796, (0 missing)
##       indus   &lt; 6.66     to the right, improve=0.2796065, (0 missing)
##       ptratio &lt; 19.65    to the right, improve=0.2600149, (0 missing)
##       nox     &lt; 0.6695   to the right, improve=0.2346383, (0 missing)
##   Surrogate splits:
##       ptratio &lt; 14.55    to the right, agree=0.884, adj=0.235, (0 split)
##       lstat   &lt; 4.915    to the right, agree=0.878, adj=0.196, (0 split)
##       zn      &lt; 87.5     to the left,  agree=0.864, adj=0.098, (0 split)
##       indus   &lt; 1.605    to the right, agree=0.864, adj=0.098, (0 split)
##       crim    &lt; 0.013355 to the right, agree=0.852, adj=0.020, (0 split)
## 
## Node number 2: 286 observations,    complexity param=0.1572513
##   mean=20.04266, MSE=37.17489 
##   left son=4 (114 obs) right son=5 (172 obs)
##   Primary splits:
##       lstat   &lt; 14.405   to the right, improve=0.3954065, (0 missing)
##       nox     &lt; 0.6695   to the right, improve=0.3012249, (0 missing)
##       crim    &lt; 8.37969  to the right, improve=0.2817286, (0 missing)
##       ptratio &lt; 20.15    to the right, improve=0.2392532, (0 missing)
##       dis     &lt; 2.4737   to the left,  improve=0.2295258, (0 missing)
##   Surrogate splits:
##       age   &lt; 84.3     to the right, agree=0.808, adj=0.518, (0 split)
##       dis   &lt; 2.23935  to the left,  agree=0.773, adj=0.430, (0 split)
##       crim  &lt; 4.067905 to the right, agree=0.762, adj=0.404, (0 split)
##       nox   &lt; 0.5765   to the right, agree=0.762, adj=0.404, (0 split)
##       indus &lt; 16.57    to the right, agree=0.759, adj=0.395, (0 split)
## 
## Node number 3: 51 observations,    complexity param=0.07485605
##   mean=37.58824, MSE=54.4677 
##   left son=6 (34 obs) right son=7 (17 obs)
##   Primary splits:
##       rm      &lt; 7.47     to the left,  improve=0.72041550, (0 missing)
##       lstat   &lt; 3.99     to the right, improve=0.34223650, (0 missing)
##       ptratio &lt; 15.05    to the right, improve=0.21227430, (0 missing)
##       rad     &lt; 2.5      to the left,  improve=0.10053340, (0 missing)
##       tax     &lt; 267      to the right, improve=0.07935891, (0 missing)
##   Surrogate splits:
##       lstat &lt; 3.99     to the right, agree=0.824, adj=0.471, (0 split)
##       indus &lt; 1.215    to the right, agree=0.706, adj=0.118, (0 split)
##       chas  &lt; 0.5      to the left,  agree=0.706, adj=0.118, (0 split)
##       tax   &lt; 225      to the right, agree=0.706, adj=0.118, (0 split)
##       crim  &lt; 1.3713   to the left,  agree=0.686, adj=0.059, (0 split)
## 
## Node number 4: 114 observations,    complexity param=0.03552748
##   mean=15.33333, MSE=21.50994 
##   left son=8 (77 obs) right son=9 (37 obs)
##   Primary splits:
##       crim    &lt; 0.69916  to the right, improve=0.3873341, (0 missing)
##       nox     &lt; 0.6615   to the right, improve=0.3541892, (0 missing)
##       dis     &lt; 2.3497   to the left,  improve=0.3182514, (0 missing)
##       ptratio &lt; 19.45    to the right, improve=0.3102781, (0 missing)
##       tax     &lt; 567.5    to the right, improve=0.2823826, (0 missing)
##   Surrogate splits:
##       ptratio &lt; 19.95    to the right, agree=0.895, adj=0.676, (0 split)
##       indus   &lt; 14.345   to the right, agree=0.868, adj=0.595, (0 split)
##       nox     &lt; 0.5825   to the right, agree=0.868, adj=0.595, (0 split)
##       tax     &lt; 397      to the right, agree=0.868, adj=0.595, (0 split)
##       rad     &lt; 16       to the right, agree=0.860, adj=0.568, (0 split)
## 
## Node number 5: 172 observations,    complexity param=0.03672387
##   mean=23.16395, MSE=23.11579 
##   left son=10 (82 obs) right son=11 (90 obs)
##   Primary splits:
##       lstat   &lt; 9.645    to the right, improve=0.24693150, (0 missing)
##       rm      &lt; 6.543    to the left,  improve=0.17749260, (0 missing)
##       ptratio &lt; 17.85    to the right, improve=0.07815189, (0 missing)
##       nox     &lt; 0.5125   to the right, improve=0.07760816, (0 missing)
##       tax     &lt; 267.5    to the right, improve=0.07238020, (0 missing)
##   Surrogate splits:
##       nox   &lt; 0.5125   to the right, agree=0.756, adj=0.488, (0 split)
##       indus &lt; 7.625    to the right, agree=0.750, adj=0.476, (0 split)
##       rm    &lt; 6.26     to the left,  agree=0.738, adj=0.451, (0 split)
##       age   &lt; 65.25    to the right, agree=0.727, adj=0.427, (0 split)
##       dis   &lt; 3.8824   to the left,  agree=0.709, adj=0.390, (0 split)
## 
## Node number 6: 34 observations
##   mean=33.15882, MSE=13.41419 
## 
## Node number 7: 17 observations
##   mean=46.44706, MSE=18.85661 
## 
## Node number 8: 77 observations,    complexity param=0.0110349
##   mean=13.33247, MSE=15.64998 
##   left son=16 (37 obs) right son=17 (40 obs)
##   Primary splits:
##       lstat &lt; 20.1     to the right, improve=0.24481010, (0 missing)
##       crim  &lt; 15.718   to the right, improve=0.23250740, (0 missing)
##       dis   &lt; 2.0037   to the left,  improve=0.17113480, (0 missing)
##       nox   &lt; 0.6615   to the right, improve=0.11757680, (0 missing)
##       rm    &lt; 5.5675   to the left,  improve=0.09054612, (0 missing)
##   Surrogate splits:
##       dis   &lt; 1.9733   to the left,  agree=0.792, adj=0.568, (0 split)
##       rm    &lt; 5.632    to the left,  agree=0.727, adj=0.432, (0 split)
##       age   &lt; 95.35    to the right, agree=0.675, adj=0.324, (0 split)
##       crim  &lt; 9.08499  to the right, agree=0.662, adj=0.297, (0 split)
##       black &lt; 396.295  to the right, agree=0.623, adj=0.216, (0 split)
## 
## Node number 9: 37 observations
##   mean=19.4973, MSE=8.034858 
## 
## Node number 10: 82 observations
##   mean=20.66098, MSE=6.55677 
## 
## Node number 11: 90 observations,    complexity param=0.01695185
##   mean=25.44444, MSE=27.29425 
##   left son=22 (83 obs) right son=23 (7 obs)
##   Primary splits:
##       age   &lt; 86.7     to the left,  improve=0.1844883, (0 missing)
##       lstat &lt; 4.46     to the right, improve=0.1773076, (0 missing)
##       dis   &lt; 3.0037   to the right, improve=0.1652768, (0 missing)
##       crim  &lt; 0.628575 to the left,  improve=0.1203635, (0 missing)
##       nox   &lt; 0.5585   to the left,  improve=0.1122403, (0 missing)
##   Surrogate splits:
##       nox     &lt; 0.5585   to the left,  agree=0.978, adj=0.714, (0 split)
##       dis     &lt; 2.1491   to the right, agree=0.978, adj=0.714, (0 split)
##       crim    &lt; 0.643205 to the left,  agree=0.967, adj=0.571, (0 split)
##       indus   &lt; 16.57    to the left,  agree=0.956, adj=0.429, (0 split)
##       ptratio &lt; 14.75    to the right, agree=0.956, adj=0.429, (0 split)
## 
## Node number 16: 37 observations
##   mean=11.2973, MSE=10.14026 
## 
## Node number 17: 40 observations
##   mean=15.215, MSE=13.37128 
## 
## Node number 22: 83 observations,    complexity param=0.01422576
##   mean=24.79277, MSE=13.56694 
##   left son=44 (55 obs) right son=45 (28 obs)
##   Primary splits:
##       rm      &lt; 6.543    to the left,  improve=0.3377388, (0 missing)
##       lstat   &lt; 5.41     to the right, improve=0.2548210, (0 missing)
##       tax     &lt; 267.5    to the right, improve=0.2210129, (0 missing)
##       ptratio &lt; 18.05    to the right, improve=0.1394682, (0 missing)
##       dis     &lt; 6.4889   to the right, improve=0.1125739, (0 missing)
##   Surrogate splits:
##       lstat   &lt; 5.055    to the right, agree=0.783, adj=0.357, (0 split)
##       ptratio &lt; 15.75    to the right, agree=0.723, adj=0.179, (0 split)
##       crim    &lt; 0.39646  to the left,  agree=0.699, adj=0.107, (0 split)
##       chas    &lt; 0.5      to the left,  agree=0.687, adj=0.071, (0 split)
##       age     &lt; 74.15    to the left,  agree=0.687, adj=0.071, (0 split)
## 
## Node number 23: 7 observations
##   mean=33.17143, MSE=125.3192 
## 
## Node number 44: 55 observations
##   mean=23.26545, MSE=8.880443 
## 
## Node number 45: 28 observations
##   mean=27.79286, MSE=9.189949</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rpart.plot</span>(boston.rpart)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-32"></span>
<img src="EksploracjaDanych_files/figure-html/unnamed-chunk-32-1.png" alt="Drzewo regresyjne pełne" width="1056" />
<p class="caption">
Rysunek 5.1: Drzewo regresyjne pełne
</p>
</div>
<p>Przycinamy drzewo…</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">printcp</span>(boston.rpart)</code></pre>
<pre><code>## 
## Regression tree:
## rpart(formula = medv ~ ., data = boston.train)
## 
## Variables actually used in tree construction:
## [1] age   crim  lstat rm   
## 
## Root node error: 26734/337 = 79.33
## 
## n= 337 
## 
##         CP nsplit rel error  xerror     xstd
## 1 0.498398      0   1.00000 1.00869 0.102595
## 2 0.157251      1   0.50160 0.54429 0.061257
## 3 0.074856      2   0.34435 0.40320 0.051393
## 4 0.036724      3   0.26949 0.31278 0.045992
## 5 0.035527      4   0.23277 0.29745 0.045608
## 6 0.016952      5   0.19724 0.25532 0.040230
## 7 0.014226      6   0.18029 0.27138 0.040991
## 8 0.011035      7   0.16607 0.27448 0.041078
## 9 0.010000      8   0.15503 0.27204 0.041193</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plotcp</span>(boston.rpart)</code></pre>
<p><img src="EksploracjaDanych_files/figure-html/unnamed-chunk-33-1.png" width="1056" /></p>
<pre class="sourceCode r"><code class="sourceCode r">boston.rpart2 &lt;-<span class="st"> </span><span class="kw">prune</span>(boston.rpart, <span class="dt">cp =</span> <span class="fl">0.016952</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rpart.plot</span>(boston.rpart2)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-34"></span>
<img src="EksploracjaDanych_files/figure-html/unnamed-chunk-34-1.png" alt="Drzewo regresyjne przycięte" width="1056" />
<p class="caption">
Rysunek 5.2: Drzewo regresyjne przycięte
</p>
</div>
<p>Predykcja na podstawie drzewa na zbiorze testowym.</p>
<pre class="sourceCode r"><code class="sourceCode r">boston.pred &lt;-<span class="st"> </span><span class="kw">predict</span>(boston.rpart2, <span class="dt">newdata =</span> boston.test)
rmse &lt;-<span class="st"> </span><span class="cf">function</span>(pred, obs) <span class="kw">sqrt</span>(<span class="dv">1</span><span class="op">/</span><span class="kw">length</span>(pred)<span class="op">*</span><span class="kw">sum</span>((pred<span class="op">-</span>obs)<span class="op">^</span><span class="dv">2</span>))
<span class="kw">rmse</span>(boston.pred, boston.test<span class="op">$</span>medv)</code></pre>
<pre><code>## [1] 5.830722</code></pre>
<p>Teraz zbudujemy model metodą bagging.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(randomForest)
boston.bag &lt;-<span class="st"> </span><span class="kw">randomForest</span>(medv<span class="op">~</span>., <span class="dt">data =</span> boston.train, 
                           <span class="dt">mtry =</span> <span class="kw">ncol</span>(boston.train)<span class="op">-</span><span class="dv">1</span>)
boston.bag</code></pre>
<pre><code>## 
## Call:
##  randomForest(formula = medv ~ ., data = boston.train, mtry = ncol(boston.train) -      1) 
##                Type of random forest: regression
##                      Number of trees: 500
## No. of variables tried at each split: 13
## 
##           Mean of squared residuals: 12.03374
##                     % Var explained: 84.83</code></pre>
<p>Predykcja na podstawie modelu</p>
<pre class="sourceCode r"><code class="sourceCode r">boston.pred2 &lt;-<span class="st"> </span><span class="kw">predict</span>(boston.bag, <span class="dt">newdata =</span> boston.test)
<span class="kw">rmse</span>(boston.pred2, boston.test<span class="op">$</span>medv)</code></pre>
<pre><code>## [1] 4.359119</code></pre>
<p>Zatem predykcja na podstawie modelu bagging jest nico lepsza niż z pojedynczego drzewa. Dodatkowo możemy ocenić ważność zmiennych użytych w budowie drzew.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">varImpPlot</span>(boston.bag)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-38"></span>
<img src="EksploracjaDanych_files/figure-html/unnamed-chunk-38-1.png" alt="Wykres ważności predyktorów" width="1056" />
<p class="caption">
Rysunek 5.3: Wykres ważności predyktorów
</p>
</div>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">importance</span>(boston.bag)</code></pre>
<pre><code>##         IncNodePurity
## crim       1335.62584
## zn           21.35274
## indus       134.28748
## chas         24.07230
## nox         423.26229
## rm        15413.69291
## age         380.78172
## dis        1204.86690
## rad          88.28151
## tax         454.99800
## ptratio     309.58412
## black       216.15512
## lstat      6217.95834</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">x<span class="op">$</span>variable.importance</code></pre>
<pre><code>##          rm       lstat       indus     ptratio        crim         age 
## 16276.30598  9170.91941  4427.10554  4039.00112  3412.53062  3170.82658 
##         nox         dis          zn         tax         rad        chas 
##  3063.70694  2681.24858  1306.29569   800.17910   539.07271   262.60146 
##       black 
##    63.78554</code></pre>
<p>W porównaniu do ważności zmiennych dla pojedynczego drzewa widać pewne różnice.</p>
</div>
<div id="lasy-losowe" class="section level2">
<h2><span class="header-section-number">5.2</span> Lasy losowe</h2>
<p>Lasy losowe są uogólnieniem metody bagging, polegającą na losowaniu dla każdego drzewa wchodzącego w skład lasu <span class="math inline">\(m\)</span> predyktorów spośród <span class="math inline">\(p\)</span> dostępnych, a następnie budowaniu drzew z wykorzystaniem tylko tych predyktorów <span class="citation">(Ho <a href="#ref-ho1995">1995</a>)</span>. Dzięki temu za każdy razem drzewo jest budowane w oparciu o nowy zestaw cech (najczęściej przyjmujemy <span class="math inline">\(m=\sqrt{p}\)</span>). W przypadku modeli bagging za każdym razem najsilniejszy predyktor wchodził w skład zbioru uczącego, a co za tym idzie również uczestniczył w tworzeniu reguł podziału. Wówczas wiele drzew zawierało reguły stosujące dany atrybut, a wtedy predykcje otrzymywane za pomocą drzew były skorelowane. Dlatego nawet duża liczba prób bootstrapowych nie zapewniała poprawy precyzji. Implementacja tej metody znajduje się w pakiecie <strong>randomForest</strong>.</p>

<div class="example">
<span id="exm:przyk52" class="example"><strong>Przykład 5.2  </strong></span>Kontynuując poprzedni przykład <a href="pochodne-drzew-decyzyjnych.html#exm:przyk51">5.1</a> możemy zbudować las losowy aby przekonać się czy nastąpi poprawa predykcji zmiennej wynikowej.
</div>

<pre class="sourceCode r"><code class="sourceCode r">boston.rf &lt;-<span class="st"> </span><span class="kw">randomForest</span>(medv<span class="op">~</span>., <span class="dt">data =</span> boston.train)
boston.rf</code></pre>
<pre><code>## 
## Call:
##  randomForest(formula = medv ~ ., data = boston.train) 
##                Type of random forest: regression
##                      Number of trees: 500
## No. of variables tried at each split: 4
## 
##           Mean of squared residuals: 12.05123
##                     % Var explained: 84.81</code></pre>
<p>Porównanie MSE na próbach uczących pomiędzy lasem losowym i modelem bagging wypada nieco na korzyść bagging.</p>
<pre class="sourceCode r"><code class="sourceCode r">boston.pred3 &lt;-<span class="st"> </span><span class="kw">predict</span>(boston.rf, <span class="dt">newdata =</span> boston.test)
<span class="kw">rmse</span>(boston.pred3, boston.test<span class="op">$</span>medv)</code></pre>
<pre><code>## [1] 3.79973</code></pre>
<p>Ważność zmiennych również się nieco różni.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">varImpPlot</span>(boston.rf)</code></pre>
<p><img src="EksploracjaDanych_files/figure-html/unnamed-chunk-41-1.png" width="1056" /></p>
</div>
<div id="boosting" class="section level2">
<h2><span class="header-section-number">5.3</span> Boosting</h2>
<p>Rozważania na temat metody <em>boosting</em> zaczęły się od pytań postawionych w publikacji <span class="citation">Kearns and Valiant (<a href="#ref-kearns1989">1989</a>)</span>, czy da się na podstawie na podstawie zbioru słabych modeli stworzyć jeden dobry? Odpowiedzi pozytywnej na nie udzielili, najpierw <span class="citation">Schapire (<a href="#ref-schapire1990">1990</a>)</span>, a potem <span class="citation">Breiman (<a href="#ref-breiman1998">1998</a>)</span>. W metodzie boosting nie stosuje się prób bootstrapowych ale odpowiednio modyfikuje się drzewo wyjściowe w kolejnych krokach na tym samym zbiorze uczącym. Algorytm dla drzewa regresyjnego jest następujący:</p>
<ol style="list-style-type: decimal">
<li>Ustal <span class="math inline">\(\hat{f}(x)=0\)</span> i <span class="math inline">\(r_i=y_i\)</span> dla każdego <span class="math inline">\(i\)</span> w zbiorze uczącym.</li>
<li>Dla <span class="math inline">\(b=1,2,\ldots, B\)</span> powtarzaj:
<ol style="list-style-type: lower-alpha">
<li>naucz drzewo <span class="math inline">\(\hat{f}^b\)</span> o <span class="math inline">\(d\)</span> regułach podziału (czyli <span class="math inline">\(d+1\)</span> liściach) na zbiorze <span class="math inline">\((X_i, r_i)\)</span>,</li>
<li>zaktualizuj drzewo do nowej “skurczonej” wersji
<span class="math display">\[\begin{equation}
 \hat{f}(x)\leftarrow \hat{f}(x)+\lambda\hat{f}^b(x),
\end{equation}\]</span></li>
<li>zaktualizuj reszty
<span class="math display">\[\begin{equation}
 r_i\leftarrow r_i-\lambda\hat{f}^b(x_i).
\end{equation}\]</span></li>
</ol></li>
<li>Wyznacz boosted model
<span class="math display">\[\begin{equation}
  \hat{f}(x) = \sum_{b=1}^B\lambda\hat{f}^b(x)
\end{equation}\]</span></li>
</ol>
<p>Uczenie drzew klasyfikacyjnego metoda boosting przebiega w podobny sposób. Wynik uczenia drzew metodą boosting zależy od trzech parametrów:</p>
<ol style="list-style-type: decimal">
<li>Liczby drzew <span class="math inline">\(B\)</span>. W przeciwieństwie do metody bagging i lasów losowych, zbyt duże <span class="math inline">\(B\)</span> może doprowadzić do przeuczenia modelu. <span class="math inline">\(B\)</span> ustala się najczęściej na podstawie walidacji krzyżowej.</li>
<li>Parametru “kurczenia” (ang. <em>shrinkage</em>) <span class="math inline">\(\lambda\)</span>. Kontroluje on szybkość uczenia się kolejnych drzew. Typowe wartości <span class="math inline">\(\lambda\)</span> to 0.01 lub 0.001. Bardzo małe <span class="math inline">\(\lambda\)</span> może wymagać dobrania większego <span class="math inline">\(B\)</span>, aby zapewnić dobrą jakość predykcyjną modelu.</li>
<li>Liczby podziałów w drzewach <span class="math inline">\(d\)</span>, która decyduje o złożoności drzewa. Bywa, że nawet <span class="math inline">\(d=1\)</span> daje dobre rezultaty, ponieważ model wówczas uczy się powoli.</li>
</ol>
<p>Implementację metody boosting można znaleźć w pakiecie <strong>gbm</strong> <span class="citation">(Greenwell et al. <a href="#ref-R-gbm">2019</a>)</span></p>

<div class="example">
<span id="exm:przyk53" class="example"><strong>Przykład 5.3  </strong></span>Metodę boosting zastosujemy do zadania predykcji ceny mieszkań na przedmieściach Bostonu. Dobór parametrów modelu będzie arbitralny, więc niekoniecznie model będzie najlepiej dopasowany.
</div>

<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(gbm)
boston.boost &lt;-<span class="st"> </span><span class="kw">gbm</span>(medv<span class="op">~</span>., <span class="dt">data =</span> boston.train,
                    <span class="dt">distribution =</span> <span class="st">&quot;gaussian&quot;</span>, 
                    <span class="dt">n.trees =</span> <span class="dv">5000</span>,
                    <span class="dt">interaction.depth =</span> <span class="dv">2</span>,
                    <span class="dt">shrinkage =</span> <span class="fl">0.01</span>)
boston.boost</code></pre>
<pre><code>## gbm(formula = medv ~ ., distribution = &quot;gaussian&quot;, data = boston.train, 
##     n.trees = 5000, interaction.depth = 2, shrinkage = 0.01)
## A gradient boosted model with gaussian loss function.
## 5000 iterations were performed.
## There were 13 predictors of which 13 had non-zero influence.</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(boston.boost)</code></pre>
<p><img src="EksploracjaDanych_files/figure-html/unnamed-chunk-43-1.png" width="1056" /></p>
<pre><code>##             var    rel.inf
## rm           rm 38.3955886
## lstat     lstat 29.4805422
## dis         dis  9.0886721
## crim       crim  5.7399540
## nox         nox  3.7754214
## ptratio ptratio  3.2740541
## black     black  3.1164954
## age         age  2.9063950
## tax         tax  1.8433918
## chas       chas  0.9067974
## indus     indus  0.7627923
## rad         rad  0.5523485
## zn           zn  0.1575472</code></pre>
<p>Predykcja na podstawie metody boosting</p>
<pre class="sourceCode r"><code class="sourceCode r">boston.pred4 &lt;-<span class="st"> </span><span class="kw">predict</span>(boston.boost, <span class="dt">newdata =</span> boston.test, <span class="dt">n.trees =</span> <span class="dv">5000</span>)
<span class="kw">rmse</span>(boston.pred4, boston.test<span class="op">$</span>medv)</code></pre>
<pre><code>## [1] 3.801233</code></pre>
<p><span class="math inline">\(RMSE\)</span> jest w tym przypadku nieco większe niż w lasach losowych ale sporo mniejsze niż w metodzie bagging. Wszystkie metody wzmacnianych drzew dają wyniki lepsze niż pojedyncze drzewa.</p>

</div>
</div>
<h3>Bibliografia</h3>
<div id="refs" class="references">
<div id="ref-breiman1996">
<p>Breiman, Leo. 1996. “Bagging Predictors.” <em>Machine Learning</em> 24 (2): 123–40. <a href="https://doi.org/10.1007/BF00058655">https://doi.org/10.1007/BF00058655</a>.</p>
</div>
<div id="ref-R-ipred">
<p>Peters, Andrea, and Torsten Hothorn. 2018. <em>Ipred: Improved Predictors</em>. <a href="https://CRAN.R-project.org/package=ipred">https://CRAN.R-project.org/package=ipred</a>.</p>
</div>
<div id="ref-R-las">
<p>Liaw, Andy, and Matthew Wiener. 2002. “Classification and Regression by randomForest.” <em>R News</em> 2 (3): 18–22. <a href="https://CRAN.R-project.org/doc/Rnews/">https://CRAN.R-project.org/doc/Rnews/</a>.</p>
</div>
<div id="ref-R-MASS">
<p>Venables, W. N., and B. D. Ripley. 2002. <em>Modern Applied Statistics with S</em>. Fourth. New York: Springer. <a href="http://www.stats.ox.ac.uk/pub/MASS4">http://www.stats.ox.ac.uk/pub/MASS4</a>.</p>
</div>
<div id="ref-ho1995">
<p>Ho, Tin Kam. 1995. “Random Decision Forests.” In <em>Proceedings of 3rd International Conference on Document Analysis and Recognition</em>, 1:278–82. IEEE.</p>
</div>
<div id="ref-kearns1989">
<p>Kearns, M., and L. G. Valiant. 1989. “Crytographic Limitations on Learning Boolean Formulae and Finite Automata.” <em>Annual ACM Symposium on Theory of Computing</em>, 433. <a href="http://search.ebscohost.com/login.aspx?direct=true&amp;db=edb&amp;AN=73725380&amp;lang=pl&amp;site=eds-live&amp;scope=site">http://search.ebscohost.com/login.aspx?direct=true&amp;db=edb&amp;AN=73725380&amp;lang=pl&amp;site=eds-live&amp;scope=site</a>.</p>
</div>
<div id="ref-schapire1990">
<p>Schapire, Robert E. 1990. “The Strength of Weak Learnability.” <em>Machine Learning</em> 5 (2): 197–227. <a href="https://doi.org/10.1007/BF00116037">https://doi.org/10.1007/BF00116037</a>.</p>
</div>
<div id="ref-breiman1998">
<p>Breiman, Leo. 1998. “Arcing Classifier (with Discussion and a Rejoinder by the Author).” <em>Ann. Statist.</em> 26 (3): 801–49. <a href="https://doi.org/10.1214/aos/1024691079">https://doi.org/10.1214/aos/1024691079</a>.</p>
</div>
<div id="ref-R-gbm">
<p>Greenwell, Brandon, Bradley Boehmke, Jay Cunningham, and GBM Developers. 2019. <em>Gbm: Generalized Boosted Regression Models</em>. <a href="https://CRAN.R-project.org/package=gbm">https://CRAN.R-project.org/package=gbm</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="17">
<li id="fn17"><p>chyba tylko dla drugiej metody istniej dobre polskie tłumaczenie nazwy - las losowy<a href="pochodne-drzew-decyzyjnych.html#fnref17" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="drzewa-decyzyjne.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="klasyfikatory-liniowe.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["EksploracjaDanych.pdf"],
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"search": true,
"toolbar": {
"position": "fixed"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
