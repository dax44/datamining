[
["index.html", "Eksploracja danych WstÄ™p O ksiÄ…Å¼ce Zakres przedmiotu Zakres technik stosowanych w data mining Etapy eksploracji danych", " Eksploracja danych Dariusz Majerek Katedra Matematyki Stosowanej WydziaÅ‚ Podstaw Techniki Politechnika Lubelskad.majerek@pollub.pl 2019-03-04 WstÄ™p O ksiÄ…Å¼ce Niniejsza ksiÄ…Å¼ka powstaÅ‚a na bazie doÅ›wiadczeÅ„ autora, a gÅ‚Ã³wnym jej celem jest przybliÅ¼enie czytelnikowi podstaw z dziedziny Data mining studentom kierunku Matematyka Politechniki Lubelskiej. BÄ™dzie Å‚Ä…czyÄ‡ w sobie zarÃ³wno treÅ›ci teoretyczne zwiÄ…zane z przedstawianymi etapami eksploracji danych i budowÄ… modeli, jak i praktyczne wskazÃ³wki dotczÄ…ce budowy modeli w Å›rodowisku R (R Core Team 2018). Podane zostanÄ… rÃ³wnieÅ¼ wskazÃ³wki, jak raportowaÄ‡ wyniki analiz i jak dokonaÄ‡ wÅ‚aÅ›ciwych ilustracji wynikÃ³w. Bardzo uÅ¼yteczny w napisaniu ksiÄ…Å¼ki byÅ‚y pakiety programu R: bookdown (Xie 2018a), knitr (Xie 2018b) oraz pakiet rmarkdown (Allaire et al. 2018). Zakres przedmiotu Przedmiot Eksploracja danych bÄ™dzie obejmowaÅ‚ swoim zakresem eksploracjÄ™ i wizualizacjÄ™ danych oraz uczenie maszynowe. Eksploracja danych ma na celu pozyskiwanie i systematyzacjÄ™ wiedzy pochodzÄ…cej z danych. Odbywa siÄ™ ona gÅ‚Ã³wnie przy uÅ¼yciu technik statystycznych, rachunku prawdopodobieÅ„stwa i metod z zakresu baz danych. Natomiast uczenie maszynowe, to gaÅ‚Ä…Åº nauki (obejmuje nie tylko statystykÄ™, choÄ‡ to na niej siÄ™ gÅ‚Ã³wnie opiera) dotyczÄ…cej budowy modeli zdolnych do rozpoznawania wzorcÃ³w, przewidywania wartoÅ›ci i klasyfikacji obiektÃ³w. Data mining to szybko rosnaca grupa metod analizy danych rozwijana nie tylko przez statystykÃ³w ale rÃ³wnieÅ¼ przez biologÃ³w, genetykÃ³w, cybernetykÃ³w, informatykÃ³w, ekonomistÃ³w, osoby pracujace nad rozpoznawaniem obrazÃ³w i wiele innych grup zawodowych. W dzisiejszych czasch trudno sobie wyobraziÄ‡ Å¼ycie bez sztucznej inteligencji. Towarzyszy ona nam w codziennym, Å¼yciu kiedy korzystamy z telefonÃ³w komÃ³rkowych, wyszukiwarek internetowych, robotÃ³w sprzÄ…tajÄ…cych, automatycznych samochodÃ³w, nawigacji czy gier komputerowych. Lista ta jest niepeÅ‚na i stale siÄ™ wydÅ‚uÅ¼a ğŸ˜„. href=â€œhttps://twitter.com/i/status/1091069356367200256â€&gt;January 31, 2019 Zakres technik stosowanych w data mining statystyka opisowa wielowymiarowa analiza danych analiza szeregÃ³w czasowych analiza danych przestrzennych reguÅ‚y asocjacji uczenie maszynowe1, w tym: klasyfikacja predykcja analiza skupieÅ„ text mining i wiele innych ğŸ“ˆ Figure .: PrzykÅ‚ad nienadzorowanego uczenia maszynowego. Å¹rÃ³dÅ‚o:https://analyticstraining.com/cluster-analysis-for-business/ href=â€œhttps://twitter.com/i/status/1097199751072690176â€&gt;Ferbruary 17, 2019 Etapy eksploracji danych Figure .: Etapy eksploracji danych (Kavakiotis et al. 2017) Czyszczenie danych - polega na usuwaniu brakÃ³w danych, usuwaniu staÅ‚ych zmiennych, imputacji brakÃ³w danych oraz przygotowaniu danych do dalszych analiz. Integracja danych - Å‚Ä…czenie danych pochodzÄ…cych z rÃ³Å¼nych ÅºrÃ³deÅ‚. Selekcja danych - wybÃ³r z bazy tych danych, ktÃ³re sÄ… potrzebne do dalszych analiz. Transformacja danych - przeksztaÅ‚cenie i konsolidacja danych do postaci przydatnej do eksploracji. Eksploracja danych - zastosowanie technik wymienionych wczeÅ›niej w celu odnalezienia wzorcÃ³w2 i zaleÅ¼noÅ›ci. Ewaluacja modeli - ocena poprawnoÅ›ci modeli oraz wzorcÃ³w z nich uzyskanych. Wizualizacja wynikÃ³w - graficzne przedstawienie odkrytych wzorcÃ³w. WdraÅ¼anie modeli - zastosowanie wyznaczonych wzorcÃ³w. Bibliografia "],
["roz1.html", "1 Import danych 1.1 PrzykÅ‚ad", " 1 Import danych Åšrodowisko R pozwala na import i export plikÃ³w o rÃ³Å¼nych rozszerzeniach (txt, csv, xls, xlsx, sav, xpt, dta, itd.)3. W tym celu czasami trzeba zainstalowaÄ‡ pakiety rozszerzajÄ…ce podstawowe moÅ¼liwoÅ›ci R-a. Najnowsza4 wersja programu RStudio (v. 1.1.463)5 pozwala na wczytanie danych z popularnych ÅºrÃ³deÅ‚ za pomocÄ… GUI. Figure 1.1: NarzÄ™dzie do importu plikÃ³w programu RStudio JeÅ›li dane sÄ… zapisane w trybie tekstowym (np. txt, csv), to wczytujemy je w nastÄ™pujÄ…cy sposÃ³b dane1 &lt;- read.table(&quot;data/dane1.txt&quot;, header = T) head(dane1) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa dane2 &lt;- read.csv2(&quot;data/dane1.csv&quot;, header = T) head(dane2) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa # funkcja pakietu readr wczytuje plik jako ramkÄ™ danych w formacie tibble # pakiet readr jest czÄ™siÄ… wiÄ™kszego pakietu tidyverse, # ktÃ³ry zostaÅ‚ wczytany wczsniej dane3 &lt;- read_csv2(&quot;data/dane1.csv&quot;) dane3 ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## # ... with 140 more rows JeÅ›li dane sÄ… przechowywane w pliku Excel (np. xlsx), to importujemy je za pomocÄ… funkcji read_excel pakietu readxl. DomyÅ›lnie jest wczytywany arkusz pierwszy ale jeÅ›li zachodzi taka potrzeba, to moÅ¼na ustaliÄ‡, ktÃ³ry arkusz pliku Excel ma byÄ‡ wczytany za pomocÄ… paramteru sheet, np. sheet=3, co oznacza, Å¼e zostanie wczytany trzeci arkusz pliku. Figure 1.2: Fragment pliku Excel PoniewaÅ¼ w pliku dane1.xlsx braki danych zostaÅ‚y zakodowane znakami BD oraz -, to naleÅ¼y ten fakt przekazaÄ‡ funkcji, aby poprawnie wczytaÄ‡ braki danych. W przeciwnym przypadku zmienne zawierajÄ…ce braki tak kodowane, bÄ™dÄ… wczytane jako zmienne znakowe. library(readxl) dane4 &lt;- read_excel(&quot;data/dane1.xlsx&quot;, na = c(&quot;BD&quot;, &quot;-&quot;)) dane4 ## # A tibble: 150 x 5 ## `DÅ‚ugoÅ›Ä‡ kielic~ `SzerokoÅ›Ä‡ kiel~ `DÅ‚ugoÅ›Ä‡ pÅ‚atka` `SzerokoÅ›Ä‡ pÅ‚at~ ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5.1 3.5 1.4 0.2 ## 2 4.9 3 1.4 0.2 ## 3 4.7 3.2 1.3 0.2 ## 4 4.6 3.1 1.5 0.2 ## 5 5 3.6 1.4 0.2 ## 6 5.4 3.9 1.7 0.4 ## 7 NA NA 1.4 0.3 ## 8 5 3.4 1.5 0.2 ## 9 4.4 2.9 1.4 0.2 ## 10 4.9 3.1 1.5 0.1 ## # ... with 140 more rows, and 1 more variable: Gatunki &lt;chr&gt; Istniej oczywiÅ›cie jeszcze wiele innych fomatÃ³w danych, charakterystycznych dla programÃ³w, w ktÃ³rych sÄ… traktowane jako domyÅ›lne.6 W szczegÃ³lny sposÃ³b naleÅ¼y zwrÃ³ciÄ‡ uwagÄ™ na pliki o rozszerzeniu RData lub rda7 oraz pliki rds. Pliki rda sÅ‚uÅ¼Ä… do przechowywania obiektÃ³w programu R. MogÄ… to byÄ‡ pliki danych ale rÃ³wnieÅ¼ obiekty graficzne (typu wyniki funkcji ggplot), modele (np. wynik funkcji lm()), zdefiniowane funkcje i wszystkie inne obiekty, ktÃ³re da siÄ™ zapisaÄ‡ w Å›rodowisku R. Ponadto pliki rda pozawalajÄ… na zapisanie wilu obiektÃ³w w jednym pliku. Pliki o rozszerzeniu rds majÄ… podobnÄ… funkcjÄ™ z tym, Å¼e pozwalajÄ… na przechowywanie tylko jednego obiektu. # wszystkie wczytane wczeÅ›niej pliki zapisuje w jednym pliku save(dane1, dane2, dane3, dane4, file = &quot;data/dane.rda&quot;) # plik rda zostaÅ‚ zapisany list.files(path = &quot;data/&quot;) ## [1] &quot;algae.csv&quot; &quot;Analysis.txt&quot; &quot;dane.rda&quot; &quot;dane1.csv&quot; ## [5] &quot;dane1.txt&quot; &quot;dane1.xlsx&quot; &quot;dane4.rds&quot; &quot;dane4.sav&quot; # usuwam dane ze Å›rodowiska R rm(dane1, dane2, dane3, dane4) # sprawdzam co jest wczytane do R ls() ## character(0) # wczytujÄ™ plik rda load(&quot;data/dane.rda&quot;) # jeszcze raz sprawdzam co jest wczytane do R ls() ## [1] &quot;dane1&quot; &quot;dane2&quot; &quot;dane3&quot; &quot;dane4&quot; ZapisujÄ…c obiekty jako oddzielne pliki, moÅ¼na przy wczytywaniu nadawaÄ‡ im nazwy. rm(dane1, dane2, dane3) ls() ## [1] &quot;dane4&quot; saveRDS(dane4, file = &quot;data/dane4.rds&quot;) nowe_dane &lt;- readRDS(&quot;data/dane4.rds&quot;) nowe_dane ## # A tibble: 150 x 5 ## `DÅ‚ugoÅ›Ä‡ kielic~ `SzerokoÅ›Ä‡ kiel~ `DÅ‚ugoÅ›Ä‡ pÅ‚atka` `SzerokoÅ›Ä‡ pÅ‚at~ ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5.1 3.5 1.4 0.2 ## 2 4.9 3 1.4 0.2 ## 3 4.7 3.2 1.3 0.2 ## 4 4.6 3.1 1.5 0.2 ## 5 5 3.6 1.4 0.2 ## 6 5.4 3.9 1.7 0.4 ## 7 NA NA 1.4 0.3 ## 8 5 3.4 1.5 0.2 ## 9 4.4 2.9 1.4 0.2 ## 10 4.9 3.1 1.5 0.1 ## # ... with 140 more rows, and 1 more variable: Gatunki &lt;chr&gt; OprÃ³cz wielu zalet takiego sposobu importu i eksportu danych jest jedna powaÅ¼na wada, pliki te moÅ¼na odczytaÄ‡ jedynie za pomocÄ… R. OsobiÅ›cie polecam stosowaÄ‡ do importu i eksportu danych plikÃ³w w takich formatach, ktÃ³re mogÄ… przeczytaÄ‡ wszyscy. Jak dotÄ…d widaÄ‡ do importu rÃ³Å¼nych formatÃ³w danych potrzebujemy rÃ³Å¼nych funkcji, czasami nawet z rÃ³Å¼nych pakietÃ³w. Istnieje rozwiÄ…zanie tego poroblemu ğŸ˜† library(rio) dane1 &lt;- import(&quot;data/dane1.txt&quot;) head(dane1) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa dane2 &lt;- import(&quot;data/dane1.csv&quot;, dec = &quot;,&quot;) # dane1.csv miaÅ‚y , jako znak rozdzielajÄ…cy cechÄ™ i mantysÄ™ liczb # dlatego wÅ‚Ä…czamy parametr dec head(dane2) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa dane3 &lt;- import(&quot;data/dane1.xlsx&quot;, na=c(&quot;BD&quot;,&quot;-&quot;)) head(dane3) ## DÅ‚ugoÅ›Ä‡ kielicha SzerokoÅ›Ä‡ kielicha DÅ‚ugoÅ›Ä‡ pÅ‚atka SzerokoÅ›Ä‡ pÅ‚atka ## 1 5.1 3.5 1.4 0.2 ## 2 4.9 3.0 1.4 0.2 ## 3 4.7 3.2 1.3 0.2 ## 4 4.6 3.1 1.5 0.2 ## 5 5.0 3.6 1.4 0.2 ## 6 5.4 3.9 1.7 0.4 ## Gatunki ## 1 setosa ## 2 setosa ## 3 setosa ## 4 setosa ## 5 setosa ## 6 setosa dane4 &lt;- import(&quot;data/dane4.rds&quot;) dane4 ## # A tibble: 150 x 5 ## `DÅ‚ugoÅ›Ä‡ kielic~ `SzerokoÅ›Ä‡ kiel~ `DÅ‚ugoÅ›Ä‡ pÅ‚atka` `SzerokoÅ›Ä‡ pÅ‚at~ ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5.1 3.5 1.4 0.2 ## 2 4.9 3 1.4 0.2 ## 3 4.7 3.2 1.3 0.2 ## 4 4.6 3.1 1.5 0.2 ## 5 5 3.6 1.4 0.2 ## 6 5.4 3.9 1.7 0.4 ## 7 NA NA 1.4 0.3 ## 8 5 3.4 1.5 0.2 ## 9 4.4 2.9 1.4 0.2 ## 10 4.9 3.1 1.5 0.1 ## # ... with 140 more rows, and 1 more variable: Gatunki &lt;chr&gt; Lista moÅ¼liwoÅ›ci jakÄ… daje nam pakiet rio (Chan and Leeper 2018) jest niemal nieograniczona:8 Comma-separated data (.csv), using fread or, if fread = FALSE, read.table with row.names = FALSE and stringsAsFactors = FALSE Pipe-separated data (.psv), using fread or, if fread = FALSE, read.table with sep = â€˜|â€™, row.names = FALSE and stringsAsFactors = FALSE Tab-separated data (.tsv), using fread or, if fread = FALSE, read.table with row.names = FALSE and stringsAsFactors = FALSE SAS (.sas7bdat), using read_sas. SAS XPORT (.xpt), using read_xpt or, if haven = FALSE, read.xport. SPSS (.sav), using read_sav. If haven = FALSE, read.spss can be used. Stata (.dta), using read_dta. If haven = FALSE, read.dta can be used. SAS XPORT (.xpt), using read.xport. SPSS Portable Files (.por), using read_por. Excel (.xls and .xlsx), using read_excel. Use which to specify a sheet number. For .xlsx files, it is possible to set readxl = FALSE, so that read.xlsx can be used instead of readxl (the default). R syntax object (.R), using dget Saved R objects (.RData,.rda), using load for single-object .Rdata files. Use which to specify an object name for multi-object .Rdata files. This can be any R object (not just a data frame). Serialized R objects (.rds), using readRDS. This can be any R object (not just a data frame). Epiinfo (.rec), using read.epiinfo Minitab (.mtp), using read.mtp Systat (.syd), using read.systat â€œXBASEâ€ database files (.dbf), using read.dbf Weka Attribute-Relation File Format (.arff), using read.arff Data Interchange Format (.dif), using read.DIF Fortran data (no recognized extension), using read.fortran Fixed-width format data (.fwf), using a faster version of read.fwf that requires a widths argument and by default in rio has stringsAsFactors = FALSE. If readr = TRUE, import will be performed using read_fwf, where widths should be: NULL, a vector of column widths, or the output of fwf_empty, fwf_widths, or fwf_positions. gzip comma-separated data (.csv.gz), using read.table with row.names = FALSE and stringsAsFactors = FALSE CSVY (CSV with a YAML metadata header) using read_csvy. Feather R/Python interchange format (.feather), using read_feather Fast storage (.fst), using read.fst JSON (.json), using fromJSON Matlab (.mat), using read.mat EViews (.wf1), using readEViews OpenDocument Spreadsheet (.ods), using read_ods. Use which to specify a sheet number. Single-table HTML documents (.html), using read_html. The data structure will only be read correctly if the HTML file can be converted to a list via as_list. Shallow XML documents (.xml), using read_xml. The data structure will only be read correctly if the XML file can be converted to a list via as_list. YAML (.yml), using yaml.load Clipboard import (on Windows and Mac OS), using read.table with row.names = FALSE Google Sheets, as Comma-separated data (.csv) 1.1 PrzykÅ‚ad PoniÅ¼sza ilustracja przedstawia fragment pliku danych Analysis.txt zawierajÄ…cego pewne bÅ‚Ä™dy, ktÃ³re naleÅ¼y naprawiÄ‡ na etapie importu danych. Po pierwsze brakuje w nim nazw zmiennych9. PoszczegÃ³lne kolumny nazywajÄ… siÄ™ nastÄ™pujÄ…co: season, size, speed, mxPH, mnO2, Cl, NO3, NH4, oPO4, PO4, Chla, a1, a2, a3, a4, a5, a6, a7. Naszym zadaniem jest import tego pliku z jednoczesnÄ… obsÅ‚ugÄ… brakÃ³w10 oraz nadaniem nagÅ‚Ã³wkÃ³w kolumn. Plik Analisis.txt jest umieszczony w kagalogu data/. Z racji, Å¼e plik dotyczy glonÃ³w, to dane zapiszemy pod nazwÄ… algae. Figure 1.3: Fragment pliku danych Analisis.txt algae &lt;- import(&#39;data/Analysis.txt&#39;, header=F, dec=&#39;.&#39;, col.names=c(&#39;season&#39;,&#39;size&#39;,&#39;speed&#39;,&#39;mxPH&#39;,&#39;mnO2&#39;,&#39;Cl&#39;, &#39;NO3&#39;,&#39;NH4&#39;,&#39;oPO4&#39;,&#39;PO4&#39;,&#39;Chla&#39;,&#39;a1&#39;,&#39;a2&#39;, &#39;a3&#39;,&#39;a4&#39;,&#39;a5&#39;,&#39;a6&#39;,&#39;a7&#39;), na.strings=c(&#39;XXXXXXX&#39;)) head(algae) ## season size speed mxPH mnO2 Cl NO3 NH4 oPO4 PO4 Chla ## 1 winter small medium 8.00 9.8 60.800 6.238 578.000 105.000 170.000 50.0 ## 2 spring small medium 8.35 8.0 57.750 1.288 370.000 428.750 558.750 1.3 ## 3 autumn small medium 8.10 11.4 40.020 5.330 346.667 125.667 187.057 15.6 ## 4 spring small medium 8.07 4.8 77.364 2.302 98.182 61.182 138.700 1.4 ## 5 autumn small medium 8.06 9.0 55.350 10.416 233.700 58.222 97.580 10.5 ## 6 winter small high 8.25 13.1 65.750 9.248 430.000 18.250 56.667 28.4 ## a1 a2 a3 a4 a5 a6 a7 ## 1 0.0 0.0 0.0 0.0 34.2 8.3 0.0 ## 2 1.4 7.6 4.8 1.9 6.7 0.0 2.1 ## 3 3.3 53.6 1.9 0.0 0.0 0.0 9.7 ## 4 3.1 41.0 18.9 0.0 1.4 0.0 1.4 ## 5 9.2 2.9 7.5 0.0 7.5 4.1 1.0 ## 6 15.1 14.6 1.4 0.0 22.5 12.6 2.9 summary(algae) ## season size speed mxPH ## Length:200 Length:200 Length:200 Min. :5.600 ## Class :character Class :character Class :character 1st Qu.:7.700 ## Mode :character Mode :character Mode :character Median :8.060 ## Mean :8.012 ## 3rd Qu.:8.400 ## Max. :9.700 ## NA&#39;s :1 ## mnO2 Cl NO3 NH4 ## Min. : 1.500 Min. : 0.222 Min. : 0.050 Min. : 5.00 ## 1st Qu.: 7.725 1st Qu.: 10.981 1st Qu.: 1.296 1st Qu.: 38.33 ## Median : 9.800 Median : 32.730 Median : 2.675 Median : 103.17 ## Mean : 9.118 Mean : 43.636 Mean : 3.282 Mean : 501.30 ## 3rd Qu.:10.800 3rd Qu.: 57.824 3rd Qu.: 4.446 3rd Qu.: 226.95 ## Max. :13.400 Max. :391.500 Max. :45.650 Max. :24064.00 ## NA&#39;s :2 NA&#39;s :10 NA&#39;s :2 NA&#39;s :2 ## oPO4 PO4 Chla a1 ## Min. : 1.00 Min. : 1.00 Min. : 0.200 Min. : 0.00 ## 1st Qu.: 15.70 1st Qu.: 41.38 1st Qu.: 2.000 1st Qu.: 1.50 ## Median : 40.15 Median :103.29 Median : 5.475 Median : 6.95 ## Mean : 73.59 Mean :137.88 Mean : 13.971 Mean :16.92 ## 3rd Qu.: 99.33 3rd Qu.:213.75 3rd Qu.: 18.308 3rd Qu.:24.80 ## Max. :564.60 Max. :771.60 Max. :110.456 Max. :89.80 ## NA&#39;s :2 NA&#39;s :2 NA&#39;s :12 ## a2 a3 a4 a5 ## Min. : 0.000 Min. : 0.000 Min. : 0.000 Min. : 0.000 ## 1st Qu.: 0.000 1st Qu.: 0.000 1st Qu.: 0.000 1st Qu.: 0.000 ## Median : 3.000 Median : 1.550 Median : 0.000 Median : 1.900 ## Mean : 7.458 Mean : 4.309 Mean : 1.992 Mean : 5.064 ## 3rd Qu.:11.375 3rd Qu.: 4.925 3rd Qu.: 2.400 3rd Qu.: 7.500 ## Max. :72.600 Max. :42.800 Max. :44.600 Max. :44.400 ## ## a6 a7 ## Min. : 0.000 Min. : 0.000 ## 1st Qu.: 0.000 1st Qu.: 0.000 ## Median : 0.000 Median : 1.000 ## Mean : 5.964 Mean : 2.495 ## 3rd Qu.: 6.925 3rd Qu.: 2.400 ## Max. :77.600 Max. :31.600 ## export(algae, file = &quot;data/algae.csv&quot;) Bibliografia "],
["przygotowanie-danych.html", "2 Przygotowanie danych 2.1 Korekta zbioru danych 2.2 PrzykÅ‚ad", " 2 Przygotowanie danych 2.1 Korekta zbioru danych Dane, ktÃ³re importujemy z zewnÄ™trznego ÅºrÃ³dÅ‚a najczÄ™Å›ciej nie speÅ‚niajÄ… formatÃ³w obowiÄ…zujÄ…cych w R. CzÄ™sto zmienne zawierajÄ… niedopuszczalne znaki szczegÃ³lne, odstÄ™py w nazwach, powtÃ³rzone nazwy kolumn, nazwy zmiennych zaczynajÄ…ce siÄ™ od liczby, czy puste wiersze lub kolumny. Przed przystÄ…pieniem do analizy zbioru naleÅ¼y rozwaÅ¼yÄ‡ ewentualne poprawki nazw zmiennych, czy usuniÄ™cie pustych kolumn i wierszy. NiektÃ³rych czynnoÅ›ci moÅ¼na dokonaÄ‡ juÅ¼ na etapie importu danych, stosujÄ…c pewne pakiety oraz nowe funkcjonalnoÅ›ci Å›rodowiska RStudio. W wiÄ™kszoÅ›ci przypadkÃ³w uchroni nas to od Å¼mudnego przeksztaÅ‚cania typÃ³w zmiennych. OczywiÅ›cie wszystkie te czynnoÅ›ci czyszczenia danych moÅ¼na rÃ³wnieÅ¼ dokonaÄ‡ juÅ¼ po imporcie danych, za pomocÄ… odpowiednich komend R. ## przykÅ‚adowe niepoÅ¼Ä…dane nazwy zmiennych test_df &lt;- as.data.frame(matrix(rnorm(18),ncol = 6)) names(test_df) &lt;- c(&quot;hIgHlo&quot;, &quot;REPEAT VALUE&quot;, &quot;REPEAT VALUE&quot;, &quot;% successful (2009)&quot;, &quot;abc@!*&quot;, &quot;&quot;) test_df ## hIgHlo REPEAT VALUE REPEAT VALUE % successful (2009) abc@!* ## 1 -1.1693163 -1.3091785 0.2473195 -0.6224286 -0.1530779 ## 2 0.5538419 0.3305905 -0.4204336 1.8724094 -1.2612693 ## 3 1.3161568 -0.2766532 0.6783398 -1.4438942 0.2730345 ## ## 1 -0.7672703 ## 2 0.1413075 ## 3 -0.3313479 ## do poprawy nazw zmiennych uÅ¼yjemy funkcji make.names names(test_df) &lt;- make.names(names(test_df)) test_df ## hIgHlo REPEAT.VALUE REPEAT.VALUE X..successful..2009. abc... ## 1 -1.1693163 -1.3091785 0.2473195 -0.6224286 -0.1530779 ## 2 0.5538419 0.3305905 -0.4204336 1.8724094 -1.2612693 ## 3 1.3161568 -0.2766532 0.6783398 -1.4438942 0.2730345 ## X ## 1 -0.7672703 ## 2 0.1413075 ## 3 -0.3313479 Efekt koÅ„cowy choÄ‡ skuteczny to nie jest zadowalajÄ…cy. Czyszczenia nazw zmiennych moÅ¼na teÅ¼ dokonaÄ‡ stosujÄ…c funkcjÄ™ clean_names pakietu janitor (Firke 2018). Pozwala on rÃ³wnieÅ¼ na usuwanie pustych wierszy i kolumn, znajdowanie zduplikowanych rekordÃ³w, itp. library(janitor) test_df %&gt;% # aby na staÅ‚e zmieniÄ‡ nazwy zmiennych trzeba podstawienia clean_names() ## h_ig_hlo repeat_value repeat_value_2 x_successful_2009 abc ## 1 -1.1693163 -1.3091785 0.2473195 -0.6224286 -0.1530779 ## 2 0.5538419 0.3305905 -0.4204336 1.8724094 -1.2612693 ## 3 1.3161568 -0.2766532 0.6783398 -1.4438942 0.2730345 ## x ## 1 -0.7672703 ## 2 0.1413075 ## 3 -0.3313479 # przykÅ‚adowe dane x &lt;- data.frame(w1=c(1,4,2,NA),w2=c(NA,2,3,NA), w3=c(1,NA,1,NA)) x ## w1 w2 w3 ## 1 1 NA 1 ## 2 4 2 NA ## 3 2 3 1 ## 4 NA NA NA x %&gt;% remove_empty(&quot;rows&quot;) ## w1 w2 w3 ## 1 1 NA 1 ## 2 4 2 NA ## 3 2 3 1 2.1.1 Identyfikacja brakÃ³w danych Zanim usuniemy jakiekolwiek braki w zbiorze, powinniÅ›my je najpierw zidentyfikowaÄ‡, okreÅ›liÄ‡ ich charakter, a dopiero potem ewentualnie podjÄ…Ä‡ decyzjÄ™ o uzupeÅ‚nianiu brakÃ³w. algae &lt;- rio::import(&quot;data/algae.csv&quot;) # najproÅ›ciej jest wywoÅ‚aÄ‡ summary summary(algae) ## season size speed mxPH ## Length:200 Length:200 Length:200 Min. :5.600 ## Class :character Class :character Class :character 1st Qu.:7.700 ## Mode :character Mode :character Mode :character Median :8.060 ## Mean :8.012 ## 3rd Qu.:8.400 ## Max. :9.700 ## NA&#39;s :1 ## mnO2 Cl NO3 NH4 ## Min. : 1.500 Min. : 0.222 Min. : 0.050 Min. : 5.00 ## 1st Qu.: 7.725 1st Qu.: 10.981 1st Qu.: 1.296 1st Qu.: 38.33 ## Median : 9.800 Median : 32.730 Median : 2.675 Median : 103.17 ## Mean : 9.118 Mean : 43.636 Mean : 3.282 Mean : 501.30 ## 3rd Qu.:10.800 3rd Qu.: 57.824 3rd Qu.: 4.446 3rd Qu.: 226.95 ## Max. :13.400 Max. :391.500 Max. :45.650 Max. :24064.00 ## NA&#39;s :2 NA&#39;s :10 NA&#39;s :2 NA&#39;s :2 ## oPO4 PO4 Chla a1 ## Min. : 1.00 Min. : 1.00 Min. : 0.200 Min. : 0.00 ## 1st Qu.: 15.70 1st Qu.: 41.38 1st Qu.: 2.000 1st Qu.: 1.50 ## Median : 40.15 Median :103.29 Median : 5.475 Median : 6.95 ## Mean : 73.59 Mean :137.88 Mean : 13.971 Mean :16.92 ## 3rd Qu.: 99.33 3rd Qu.:213.75 3rd Qu.: 18.308 3rd Qu.:24.80 ## Max. :564.60 Max. :771.60 Max. :110.456 Max. :89.80 ## NA&#39;s :2 NA&#39;s :2 NA&#39;s :12 ## a2 a3 a4 a5 ## Min. : 0.000 Min. : 0.000 Min. : 0.000 Min. : 0.000 ## 1st Qu.: 0.000 1st Qu.: 0.000 1st Qu.: 0.000 1st Qu.: 0.000 ## Median : 3.000 Median : 1.550 Median : 0.000 Median : 1.900 ## Mean : 7.458 Mean : 4.309 Mean : 1.992 Mean : 5.064 ## 3rd Qu.:11.375 3rd Qu.: 4.925 3rd Qu.: 2.400 3rd Qu.: 7.500 ## Max. :72.600 Max. :42.800 Max. :44.600 Max. :44.400 ## ## a6 a7 ## Min. : 0.000 Min. : 0.000 ## 1st Qu.: 0.000 1st Qu.: 0.000 ## Median : 0.000 Median : 1.000 ## Mean : 5.964 Mean : 2.495 ## 3rd Qu.: 6.925 3rd Qu.: 2.400 ## Max. :77.600 Max. :31.600 ## ## wyÅ›wietl niekompletne wiersze algae[!complete.cases(algae),] %&gt;% head() ## season size speed mxPH mnO2 Cl NO3 NH4 oPO4 PO4 Chla a1 a2 a3 ## 28 autumn small high 6.8 11.1 9.00 0.630 20 4.0 NA 2.7 30.3 1.9 0.0 ## 38 spring small high 8.0 NA 1.45 0.810 10 2.5 3.0 0.3 75.8 0.0 0.0 ## 48 winter small low NA 12.6 9.00 0.230 10 5.0 6.0 1.1 35.5 0.0 0.0 ## 55 winter small high 6.6 10.8 NA 3.245 10 1.0 6.5 NA 24.3 0.0 0.0 ## 56 spring small medium 5.6 11.8 NA 2.220 5 1.0 1.0 NA 82.7 0.0 0.0 ## 57 autumn small medium 5.7 10.8 NA 2.550 10 1.0 4.0 NA 16.8 4.6 3.9 ## a4 a5 a6 a7 ## 28 0.0 2.1 1.4 2.1 ## 38 0.0 0.0 0.0 0.0 ## 48 0.0 0.0 0.0 0.0 ## 55 0.0 0.0 0.0 0.0 ## 56 0.0 0.0 0.0 0.0 ## 57 11.5 0.0 0.0 0.0 ## policz niekompletne wiersze nrow(algae[!complete.cases(algae),]) ## [1] 16 ## sprawdzenie liczby brakÃ³w w wierszach apply(algae, 1, function(x) sum(is.na(x))) ## 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ## 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 ## 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 ## 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 ## 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 ## 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 ## 2 2 2 2 2 2 2 6 1 0 0 0 0 0 0 0 0 0 ## 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 ## 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 ## 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 ## 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 ## 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 ## 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 ## 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 ## 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 ## 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 ## 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 199 200 ## 6 0 Wiele ciekawych funkcji do eksploracji danych znajduje siÄ™ w pakiecie DMwR (Torgo 2013), ktÃ³ry zostaÅ‚ przygotowany przy okazji publikacji ksiÄ…Å¼ki Data Mining with R. ## poszukiwanie wierszy zawierajÄ…cych wiele brakÃ³w ## w tym przypadku prÃ³g wyÅ›wietlania ustawiony jest na 0.2 ## czyli 20% wszystkich kolumn library(DMwR) manyNAs(algae) ## 62 199 ## 62 199 ## tworzenie zbioru pozbawionego wierszy zawierajÄ…cych wiele brakÃ³w algae2 &lt;- algae[-manyNAs(algae), ] ## sprawdzamy liczbÄ™ wybrakowanych wierszy ktÃ³re pozostaÅ‚y nrow(algae2[!complete.cases(algae2),]) ## [1] 14 ## usuwamy wszystkie wiersze z brakami algae3 &lt;- na.omit(algae) ## wyÅ›wietl wiersze z brakami algae3[!complete.cases(algae3),] %&gt;% head() ## [1] season size speed mxPH mnO2 Cl NO3 NH4 oPO4 PO4 ## [11] Chla a1 a2 a3 a4 a5 a6 a7 ## &lt;0 rows&gt; (or 0-length row.names) ## liczba pozostaÅ‚ych wybrakowanych wierszy nrow(algae3[!complete.cases(algae3),]) ## [1] 0 ## moÅ¼na oczywiÅ›cie teÅ¼ rÄ™cznie usuwaÄ‡ wiersze (nie polecam) algae4 &lt;- algae[-c(62,199),] MoÅ¼na teÅ¼ zbudowaÄ‡ funkcjÄ™, ktÃ³ra bÄ™dzie usuwaÅ‚a braki danych wg naszego upodobania. ## najpierw budujemy funkcjÄ™ i jÄ… kompilujemy aby R mÃ³gÅ‚ ja stosowaÄ‡ ## parametr prog ustala prÃ³g odciÄ™cia wierszy czysc.dane &lt;- function(dt, prog = 0){ licz.braki &lt;- apply(dt, 1, function(x) sum(is.na(x))) czyste.dt &lt;- dt[!(licz.braki/ncol(dt)&gt;prog), ] return(czyste.dt) } ## potem jÄ… moÅ¼emy stosowaÄ‡ algae4 &lt;- czysc.dane(algae) nrow(algae4[!complete.cases(algae4),]) ## [1] 0 ## czyÅ›cimy wiersze, ktÃ³rych liczba brakÃ³w przekracza 20% wszystkich kolumn algae5 &lt;- czysc.dane(algae, prog = 0.2) nrow(algae5[!complete.cases(algae5),]) ## [1] 14 Bardzo ciekawym narzÄ™dziem do znajdowania brakÃ³w danych jest funkcja md.pattern pakietu mice (van Buuren and Groothuis-Oudshoorn 2018). Wskazuje on ile brakÃ³w wystÄ™puje w ramach kaÅ¼dej zmiennej. library(mice) md.pattern(algae) Figure 2.1: Na czerwono zaznaczone sÄ… zmienne, ktÃ³re zwierajÄ… braki danych. Liczba w wierszu po lewej stronie wykresu wskazuje ile wierszy w bazie ma danÄ… charakterystykÄ™, a liczba po prawej oznacza ile zmiennych byÅ‚o wybrakowanych ## season size speed a1 a2 a3 a4 a5 a6 a7 mxPH mnO2 NO3 NH4 oPO4 PO4 Cl ## 184 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ## 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ## 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 ## 7 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 ## 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 ## 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 ## 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 ## 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 0 ## 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 ## 0 0 0 0 0 0 0 0 0 0 1 2 2 2 2 2 10 ## Chla ## 184 1 0 ## 3 0 1 ## 1 1 1 ## 7 0 2 ## 1 1 1 ## 1 0 6 ## 1 1 1 ## 1 0 6 ## 1 1 1 ## 12 33 2.1.2 ZastÄ™powanie brakÃ³w danych ZastÄ™powanie brakÃ³w danych (zwane takÅ¼e imputacjÄ… danych) jest kolejnym etapem procesu przygotowania danych do analiz. Nie moÅ¼na jednak wyrÃ³Å¼niÄ‡ uniwersalnego sposobu zastÄ™powania brakÃ³w dla wszystkich moÅ¼liwych sytuacji. WÅ›rÃ³d statystykÃ³w panuje przekonanie, Å¼e w przypadku wystÄ…pienia brakÃ³w danych moÅ¼na zastosowaÄ‡ trzy strategie: nic nie robiÄ‡ z brakami - co wydaje siÄ™ niedorzeczne ale wcale takie nie jest, poniewaÅ¼ istnieje wiele modeli statystycznych (np. drzewa decyzyjne), ktÃ³re Å›wietnie radzÄ… sobie w sytuacji brakÃ³w danych. Niestety nie jest to sposÃ³b, ktÃ³ry moÅ¼na stosowaÄ‡ zawsze, poniewaÅ¼ sÄ… rÃ³wnieÅ¼ modele wymagajÄ…ce kompletnoÅ›ci danych jak na przykÅ‚ad sieci neuronowe. usuwaÄ‡ braki wierszami11 - to metoda, ktÃ³ra jest stosowana domyÅ›lnie w przypadku kiedy twÃ³rca modelu nie zadecyduje o innym sposobie obsÅ‚ugi luk. Metoda ta ma swojÄ… niewÄ…tpliwÄ… zaletÄ™ w postaci jasnej i prostej procedury, ale szczegÃ³lnie w przypadku niewielkich zbiorÃ³w moÅ¼e skutkowaÄ‡ obciÄ…Å¼eniem estymatorÃ³w. Nie wiemy bowiem jaka wartoÅ›Ä‡ faktycznie jest przypisana danej cesze. JeÅ›li jest to wartoÅ›Ä‡ bliska np. Å›redniej, to nie wpÅ‚ynie znaczÄ…co na obciÄ…Å¼enie estymatora wartoÅ›ci oczekiwanej. W przypadku, gdy rÃ³Å¼ni siÄ™ ona znacznie od Å›redniej tej cechy, to estymator moÅ¼e juÅ¼ wykazywaÄ‡ obciÄ…Å¼enie. Jego wielkoÅ›Ä‡ zaleÅ¼y rÃ³wnieÅ¼ od liczby usuniÄ™tych elementÃ³w. Nie jest zalecane usuwanie wielu wierszy ze zbioru danych i na podstawie okrojonego zbioru wyciÄ…ganie wnioskÃ³w o populacji, poniewaÅ¼ prÃ³ba jest wÃ³wczas znaczÄ…co inna niÅ¼ populacja. Dodatkowo jeÅ›li estymatory sÄ… wyznaczane na podstawie zbioru wyraÅºnie mniej licznego, to precyzja estymatorÃ³w wyraÅ¼ona wariancjÄ… spada. ReasumujÄ…c, jeÅ›li liczba wierszy z brakujÄ…cymi danymi jest niewielka w stosunku do caÅ‚ego zbioru, to usuwanie wierszy jest sensownym rozwiÄ…zaniem. uzupeÅ‚nianie brakÃ³w - to procedura polegajÄ…ca na zastÄ™powaniu brakÃ³w rÃ³Å¼nymi technikami. Jej niewÄ…tpliwÄ… zaletÄ… jest fakt posiadania kompletnych danych bez koniecznoÅ›ci usuwania wierszy. Niestety wiÄ…Å¼e siÄ™ to rÃ³wnieÅ¼ z pewnymi wadami. ZbiÃ³r posiadajÄ…cy wiele brakÃ³w uzupeÅ‚nianych nawet bardzo wyrafinowanymi metodami moÅ¼e cechowaÄ‡ siÄ™ zaniÅ¼onÄ… wariancjÄ… poszczegÃ³lnych cech oraz tzw. przeuczeniem12. UzupeÅ‚nianie Å›redniÄ… - braki w zakresie danej zmiennej uzupeÅ‚niamy Å›redniÄ… tej zmiennej przypadkÃ³w uzupeÅ‚nionych. algae[is.na(algae$mxPH), ] ## season size speed mxPH mnO2 Cl NO3 NH4 oPO4 PO4 Chla a1 a2 a3 a4 a5 ## 48 winter small low NA 12.6 9 0.23 10 5 6 1.1 35.5 0 0 0 0 ## a6 a7 ## 48 0 0 m &lt;- mean(algae$mxPH, na.rm = T) algae[is.na(algae$mxPH), &quot;mxPH&quot;] &lt;- m algae[is.na(algae$mxPH), ] ## [1] season size speed mxPH mnO2 Cl NO3 NH4 oPO4 PO4 ## [11] Chla a1 a2 a3 a4 a5 a6 a7 ## &lt;0 rows&gt; (or 0-length row.names) UzupeÅ‚nianie medianÄ… - braki w zakresie danej zmiennej uzupeÅ‚niamy medianÄ… tej zmiennej przypadkÃ³w uzupeÅ‚nionych. algae %&gt;% filter(is.na(Chla)) %&gt;% head ## season size speed mxPH mnO2 Cl NO3 NH4 oPO4 PO4 Chla a1 a2 a3 ## 1 winter small high 6.6 10.8 NA 3.245 10 1 6.5 NA 24.3 0.0 0.0 ## 2 spring small medium 5.6 11.8 NA 2.220 5 1 1.0 NA 82.7 0.0 0.0 ## 3 autumn small medium 5.7 10.8 NA 2.550 10 1 4.0 NA 16.8 4.6 3.9 ## 4 spring small high 6.6 9.5 NA 1.320 20 1 6.0 NA 46.8 0.0 0.0 ## 5 summer small high 6.6 10.8 NA 2.640 10 2 11.0 NA 46.9 0.0 0.0 ## 6 autumn small medium 6.6 11.3 NA 4.170 10 1 6.0 NA 47.1 0.0 0.0 ## a4 a5 a6 a7 ## 1 0.0 0 0.0 0 ## 2 0.0 0 0.0 0 ## 3 11.5 0 0.0 0 ## 4 28.8 0 0.0 0 ## 5 13.4 0 0.0 0 ## 6 0.0 0 1.2 0 algae[is.na(algae$Chla), &quot;Chla&quot;] &lt;- median(algae$Chla, na.rm = T) WypeÅ‚nianie zmiennych typu wyliczeniowego, logicznego lub znakowego odbywa siÄ™ najczÄ™Å›ciej przez dobranie w miejsce brakujÄ…cej wartoÅ›ci, elementu powtarzajÄ…cego siÄ™ najczÄ™Å›ciej wÅ›rÃ³d obiektÃ³w obserwowanych. W pakiecie DMwR istnieje funkcja centralImputation, ktÃ³ra wypeÅ‚nia braki wartoÅ›ciÄ… centralnÄ… (w przypadku zmiennych typu liczbowego - medianÄ…, a dla wartoÅ›ci logicznych, wyliczeniowych lub tekstowych - modÄ…). algae[48, &quot;season&quot;] ## [1] &quot;winter&quot; algae[48, &quot;season&quot;] &lt;- NA algae.uzup &lt;- centralImputation(algae) algae.uzup[48,] ## season size speed mxPH mnO2 Cl NO3 NH4 oPO4 PO4 Chla a1 a2 a3 ## 48 winter small low 8.011734 12.6 9 0.23 10 5 6 1.1 35.5 0 0 ## a4 a5 a6 a7 ## 48 0 0 0 0 Jeszcze innym sposobem imputacji danych sÄ… algorytmy oparte o metodÄ™ \\(k\\)-najbliÅ¼szych sÄ…siadÃ³w. Algorytm opiera siÄ™ na prostej zasadzie, uzupeÅ‚niania brakujÄ…cych wartoÅ›ci medianÄ… (w przypadku zmiennych iloÅ›ciowych) lub modÄ… (w przypadku zmiennych jakoÅ›ciowych) elementÃ³w, ktÃ³re sÄ… \\(k\\)-tymi najbliÅ¼szymi sÄ…siadami w metryce \\[\\begin{equation}\\label{knn} d(x,y)=\\sqrt{\\sum_{i=1}^{p}\\delta_i(x_i,y_i)}, \\end{equation}\\] gdzie \\(\\delta_i\\) jest odlegÅ‚oÅ›ciÄ… pomiÄ™dzy dwoma elementami ze wzglÄ™du na \\(i\\)-tÄ… cech, okreÅ›lonÄ… nastÄ™pujÄ…co \\[\\begin{equation}\\label{metryka} \\delta_i(v_1, v_2)=\\begin{cases} 1,&amp; \\text{jeÅ›li zmienna jest jakoÅ›ciowa i }v_1\\neq v_2\\\\ 0,&amp; \\text{jeÅ›li zmienna jest jakoÅ›ciowa i }v_1=v_2\\\\ (v_1-v_2)^2,&amp; \\text{jeÅ›li zmienna jest iloÅ›ciowa.} \\end{cases} \\end{equation}\\] OdlegÅ‚oÅ›ci sÄ… mierzone dla zmiennych standaryzowanych. Istnieje teÅ¼ odmiana z wagami, ktÃ³re malejÄ… wraz ze wzrostem odlegÅ‚oÅ›ci pomiÄ™dzy sÄ…siadem a uzupeÅ‚nianym elementem (np. \\(w(d)=\\exp(d)\\)). algae[48, ] ## season size speed mxPH mnO2 Cl NO3 NH4 oPO4 PO4 Chla a1 a2 a3 ## 48 &lt;NA&gt; small low 8.011734 12.6 9 0.23 10 5 6 1.1 35.5 0 0 ## a4 a5 a6 a7 ## 48 0 0 0 0 algae &lt;- algae %&gt;% mutate_if(is.character, as.factor) algae.uzup &lt;- knnImputation(algae, k = 5, scale = F, meth = &quot;median&quot;) algae.uzup[48,] ## season size speed mxPH mnO2 Cl NO3 NH4 oPO4 PO4 Chla a1 a2 a3 ## 48 summer small low 8.011734 12.6 9 0.23 10 5 6 1.1 35.5 0 0 ## a4 a5 a6 a7 ## 48 0 0 0 0 IstniejÄ… rÃ³wnieÅ¼ duÅ¼o bardziej zÅ‚oÅ¼one algorytmy imputacji danych oparte na bardziej wyrafinowanych technikach, takich jak: predykcja modelami liniowymi, nieliniowymi, analiza dyskryminacyjna, drzewa klasyfikacyjne. Dwa najbardziej znane pakiety zawierajÄ…ce funkcje do imputacji w sposÃ³b zÅ‚oÅ¼ony, to Amelia i mice. Imputacja danych z zastosowaniem pakietu mice wymaga podjÄ™cia kilku decyzji przed przystÄ…pieniem do uzupeÅ‚niania danych: Czy dane sÄ… MAR (ang. Missing At Random) czy MNAR (ang. Missing Not At Random), co oznacza, Å¼e musimy siÄ™ zastanowiÄ‡ jakie mogÅ‚y byÄ‡ ÅºrÃ³dÅ‚a brakÃ³w danych, przypadkowe czy systematyczne? NaleÅ¼y siÄ™ zdecydowaÄ‡ na formÄ™ imputacji, okreÅ›lajÄ…c strukturÄ™ zaleÅ¼noÅ›ci pomiÄ™dzy cechami oraz rozkÅ‚ad bÅ‚Ä™du danej cechy? WybraÄ‡ zbiÃ³r danych, ktÃ³ry posÅ‚uÅ¼y nam za predyktory w imputacji (nie mogÄ… zawieraÄ‡ brakÃ³w). OkreÅ›lenie, ktÃ³re niepeÅ‚ne zmienne sÄ… funkcjami innych wybrakowanych zmiennych. OkreÅ›liÄ‡ w jakiej kolejnoÅ›ci dane bÄ™dÄ… imputowane. OkreÅ›liÄ‡ parametry startowe imputacji (liczbÄ™ iteracji, warunek zbieÅ¼noÅ›ci). OkreÅ›liÄ‡ liczÄ™ imputowanych zbiorÃ³w. Ad 1. WyrÃ³Å¼niamy nastÄ™pujÄ…ce rodzaje brakÃ³w danych: MCAR (ang. Missing Completely At Random) - z definicji to braki, ktÃ³rych pojawienie siÄ™ jest kompletnie losowe. PrzykÅ‚adowo gdy osoba poproszona o wypeÅ‚nienie wieku w ankiecie bÄ™dzie rzucaÄ‡ monetÄ… czy wypeÅ‚niÄ‡ tÄ… zmiennÄ…. MAR - oznacza, Å¼e obserwowane wartoÅ›ci i wybrakowane majÄ… inne rozkÅ‚ady ale da siÄ™ je oszacowaÄ‡ na podstawie danych obserwowanych. PrzykÅ‚adowo ciÅ›nienie tÄ™tnicze u osÃ³b, ktÃ³re nie wypeÅ‚niÅ‚y tej wartoÅ›ci jest wyÅ¼sze niÅ¼ u osÃ³b, ktÃ³re wpisaÅ‚y swoje ciÅ›nienie. Okazuje siÄ™, Å¼e osoby starsze z nadciÅ›nieniem nie wypeÅ‚niaÅ‚y ankiety w tym punkcie. MNAR - jeÅ›li nie jest speÅ‚niony warunek MCAR i MAR, wÃ³wczas brak ma charakter nielosowy. PrzykÅ‚adowo respondenci osiÄ…gajÄ…cy wyÅ¼sze zarobki sukcesywnie nie wypeÅ‚niajÄ… pola â€œzarobkiâ€ i dodatkowo nie ma w ankiecie zmiennych, ktÃ³re pozwoliÅ‚yby nam ustaliÄ‡, jakie to osoby. Ad 2. Decyzja o algorytmie imputacji wynika bezpoÅ›rednio ze skali w jakiej jest mierzona dana zmienna. Ze wzglÄ™du na rodzaj cechy uÅ¼ywaÄ‡ bÄ™dziemy nastÄ™pujÄ…cych metod: Table 2.1: Zestaw metod imputacji danych stosowanych w pakiecie mice method type description pmm any Predictive.mean.matching midastouch any Weighted predictive mean matching sample any Random sample from observed values cart any Classification and regression trees rf any Random forest imputations mean numeric Unconditional mean imputation norm numeric Bayesian linear regression norm.nob numeric Linear regression ignoring model error norm.boot numeric Linear regression using bootstrap norm.predict numeric Linear regression, predicted values quadratic numeric Imputation of quadratic terms ri numeric Random indicator for nonignorable data logreg binary Logistic regression logreg.boot binary Logistic regression with bootstrap polr ordered Proportional odds model polyreg unordered Polytomous logistic regression lda unordered Linear discriminant analysis 2l.norm numeric Level-1 normal heteroscedastic 2l.lmer numeric Level-1 normal homoscedastic, lmer 2l.pan numeric Level-1 normal homoscedastic, pan 2l.bin binary Level-1 logistic, glmer 2lonly.mean numeric Level-2 class mean 2lonly.norm numeric Level-2 class normal 2lonly.pmm any Level-2 class predictive mean matching KaÅ¼dy z czterech typÃ³w danych ma swÃ³j domyÅ›lny algorytm przeznaczony do imputacji: zmienna iloÅ›ciowa - pmm zmienna dychotomiczna (stany 0 lub 1) - logreg zmienna typu wyliczeniowego (nieuporzÄ…dkowana) - polyreg zmienna typu wyliczeniowego (uporzÄ…dkowana) - polr NiewÄ…tpliwÄ… zaletÄ… metody pmm jest to, Å¼e wartoÅ›ci imputowane sÄ… ograniczone jedynie do obserwowanych wartoÅ›ci. Metody norm i norm.nob uzupeÅ‚niajÄ… brakujÄ…ce wartoÅ›ci w oparciu o model liniowy. SÄ… one szybkie i efektywne w przypadku gdy reszty modelu sÄ… zbliÅ¼one rozkÅ‚adem do normalnoÅ›ci. Druga z tych technik nie bierze pod uwagÄ™ niepewnoÅ›ci zwiÄ…zanej z modelem imputujÄ…cym. Metoda 2L.norm opiera siÄ™ na dwupoziomowym heterogenicznym modelu liniowym (skupienia sÄ… wÅ‚Ä…czone jako efekt do modelu). Technika polyreg korzysta z funkcji multinom pakietu nnet tworzÄ…cej model wielomianowy. polr opiera siÄ™ o proporcjonalny model logitowy z pakietu MASS. lda to model dyskryminacyjny klasyfikujÄ…cy obiekty na podstawie prawdopodobieÅ„stw a posteriori. Metoda sample zastÄ™puje braki losowa wybranymi wartoÅ›ciami spoÅ›rÃ³d wartoÅ›ci obserwowanych. Ad 3. Do ustalenia predyktorÃ³w w modelu mice sÅ‚uÅ¼y funkcja predictorMatrix. Po pierwsze wyÅ›wietla ona domyÅ›lny ukÅ‚ad predyktorÃ³w wÅ‚Ä…czanych do modelu. MoÅ¼na go dowolnie zmieniÄ‡ i podstawiÄ‡ do modelu imputujÄ…cego dane parametrem predictorMatrix. Zera wystÄ™pujÄ…ce w kolejnych wierszach macierzy predyktorÃ³w oznaczajÄ… pominiÄ™cie tej zmiennej przy imputacji innej zmiennej. JeÅ›li dodatkowo chcemy by jakaÅ› zmienna nie byÅ‚a imputowana, to oprÃ³cz usuniÄ™cia jej z listy predyktorÃ³w, naleÅ¼y wymazaÄ‡ jÄ… z listy metod predykcji (method). OgÃ³lne zalecenia co do tego jakie zmienne stosowaÄ‡ jako predyktory jest takie, Å¼eby braÄ‡ ich jak najwiÄ™cej. Spowoduje to, Å¼e bardziej prawdopodobny staje siÄ™ brak typu MAR a nie MNAR. Z drugiej jednak strony, nierzadko zbiory zawierajÄ… olbrzymiÄ… liczbÄ™ zmiennych i wÅ‚Ä…czanie ich wszystkich do modelu imputujÄ…cego nie bÄ™dzie miaÅ‚o sensu. Zalecenia doboru zmiennych sÄ… nastÄ™pujÄ…ce: weÅº wszystkie te zmienne, ktÃ³re sÄ… wÅ‚Ä…czane do modelu wÅ‚aÅ›ciwego, czyli tego za pomocÄ… ktÃ³rego chcesz poznaÄ‡ strukturÄ™ zaleÅ¼noÅ›ci; czasem do modelu imputujÄ…cego naleÅ¼y teÅ¼ wÅ‚Ä…czyÄ‡ interakcje zmiennych z modelu wÅ‚aÅ›ciwego; dodaj zmienne, ktÃ³re mogÄ… mieÄ‡ wpÅ‚yw na wybrakowane cechy; wÅ‚Ä…cz zmienne istotnie podnoszÄ…ce poziom wyjaÅ›nionej wariancji modelu; na koniec usuÅ„ te zmienne spoÅ›rÃ³d predyktorÃ³w, ktÃ³re same zawierajÄ… zbyt wiele brakÃ³w. Ad 4-7. Decyzje podejmowane w tych punktach zaleÅ¼Ä… istotnie od analizowanego zbioru i bÄ™dÄ… przedmiotem oddzielnych analiz w kontekÅ›cie rozwaÅ¼anych zbiorÃ³w i zadaÅ„. 2.2 PrzykÅ‚ad Dokonamy imputacji zbioru airquality z wykorzystaniem pakietÃ³w mice i VIM (Templ et al. 2019) data &lt;- airquality summary(data) ## Ozone Solar.R Wind Temp ## Min. : 1.00 Min. : 7.0 Min. : 1.700 Min. :56.00 ## 1st Qu.: 18.00 1st Qu.:115.8 1st Qu.: 7.400 1st Qu.:72.00 ## Median : 31.50 Median :205.0 Median : 9.700 Median :79.00 ## Mean : 42.13 Mean :185.9 Mean : 9.958 Mean :77.88 ## 3rd Qu.: 63.25 3rd Qu.:258.8 3rd Qu.:11.500 3rd Qu.:85.00 ## Max. :168.00 Max. :334.0 Max. :20.700 Max. :97.00 ## NA&#39;s :37 NA&#39;s :7 ## Month Day ## Min. :5.000 Min. : 1.0 ## 1st Qu.:6.000 1st Qu.: 8.0 ## Median :7.000 Median :16.0 ## Mean :6.993 Mean :15.8 ## 3rd Qu.:8.000 3rd Qu.:23.0 ## Max. :9.000 Max. :31.0 ## # tworzymy dodatkowe braki danych data[4:10,3] &lt;- rep(NA,7) data[1:5,4] &lt;- NA summary(data) ## Ozone Solar.R Wind Temp ## Min. : 1.00 Min. : 7.0 Min. : 1.700 Min. :57.00 ## 1st Qu.: 18.00 1st Qu.:115.8 1st Qu.: 7.400 1st Qu.:73.00 ## Median : 31.50 Median :205.0 Median : 9.700 Median :79.00 ## Mean : 42.13 Mean :185.9 Mean : 9.806 Mean :78.28 ## 3rd Qu.: 63.25 3rd Qu.:258.8 3rd Qu.:11.500 3rd Qu.:85.00 ## Max. :168.00 Max. :334.0 Max. :20.700 Max. :97.00 ## NA&#39;s :37 NA&#39;s :7 NA&#39;s :7 NA&#39;s :5 ## Month Day ## Min. :5.000 Min. : 1.0 ## 1st Qu.:6.000 1st Qu.: 8.0 ## Median :7.000 Median :16.0 ## Mean :6.993 Mean :15.8 ## 3rd Qu.:8.000 3rd Qu.:23.0 ## Max. :9.000 Max. :31.0 ## md.pattern(data) ## Month Day Temp Solar.R Wind Ozone ## 104 1 1 1 1 1 1 0 ## 34 1 1 1 1 1 0 1 ## 3 1 1 1 1 0 1 1 ## 1 1 1 1 1 0 0 2 ## 4 1 1 1 0 1 1 1 ## 1 1 1 1 0 1 0 2 ## 1 1 1 1 0 0 1 2 ## 3 1 1 0 1 1 1 1 ## 1 1 1 0 1 0 1 2 ## 1 1 1 0 0 0 0 4 ## 0 0 5 7 7 37 56 Do ilustracji brakÃ³w danych moÅ¼na zastosowaÄ‡ funkcje pakietu VIM. library(VIM) aggr(data, numbers=TRUE, sortVars=TRUE, labels=names(data), cex.axis=.7) ## ## Variables sorted by number of missings: ## Variable Count ## Ozone 0.24183007 ## Solar.R 0.04575163 ## Wind 0.04575163 ## Temp 0.03267974 ## Month 0.00000000 ## Day 0.00000000 Tak przedstawia siÄ™ wykres rozrzutu zmiennych Ozone i Solar.R z uwzglÄ™dnieniem poÅ‚oÅ¼enia brakÃ³w danych. marginplot(data[c(1,2)]) Dokonamy imputacji metodÄ… pmm. tempData &lt;- mice(data, maxit=50, meth=&#39;pmm&#39;, seed=44, printFlag = F) summary(tempData) ## Class: mids ## Number of multiple imputations: 5 ## Imputation methods: ## Ozone Solar.R Wind Temp Month Day ## &quot;pmm&quot; &quot;pmm&quot; &quot;pmm&quot; &quot;pmm&quot; &quot;&quot; &quot;&quot; ## PredictorMatrix: ## Ozone Solar.R Wind Temp Month Day ## Ozone 0 1 1 1 1 1 ## Solar.R 1 0 1 1 1 1 ## Wind 1 1 0 1 1 1 ## Temp 1 1 1 0 1 1 ## Month 1 1 1 1 0 1 ## Day 1 1 1 1 1 0 PoniewaÅ¼, funkcja mice domyÅ›lnie dokonuje 5 kompletnych imputacji, moÅ¼emy siÄ™ przekonaÄ‡ jak bardzo rÃ³Å¼niÄ… siÄ™ poszczegÃ³lne imputacje i zdecydowaÄ‡ siÄ™ na jednÄ… z nich. head(tempData$imp$Ozone) ## 1 2 3 4 5 ## 5 21 20 7 36 13 ## 10 21 16 44 22 21 ## 25 14 14 14 6 8 ## 26 23 18 8 19 14 ## 27 37 23 21 7 9 ## 32 63 23 7 52 39 Ostatecznie imputacji dokonujemy wybierajÄ…c jeden z zestawÃ³w danych uzupeÅ‚niajÄ…cych (np. pierwszy). completedData &lt;- mice::complete(tempData, 1) summary(completedData) ## Ozone Solar.R Wind Temp ## Min. : 1.0 Min. : 7.0 Min. : 1.700 Min. :57.00 ## 1st Qu.: 20.0 1st Qu.:115.0 1st Qu.: 7.400 1st Qu.:73.00 ## Median : 32.0 Median :212.0 Median : 9.700 Median :79.00 ## Mean : 42.5 Mean :187.9 Mean : 9.931 Mean :78.14 ## 3rd Qu.: 59.0 3rd Qu.:259.0 3rd Qu.:11.500 3rd Qu.:85.00 ## Max. :168.0 Max. :334.0 Max. :20.700 Max. :97.00 ## Month Day ## Min. :5.000 Min. : 1.0 ## 1st Qu.:6.000 1st Qu.: 8.0 ## Median :7.000 Median :16.0 ## Mean :6.993 Mean :15.8 ## 3rd Qu.:8.000 3rd Qu.:23.0 ## Max. :9.000 Max. :31.0 Za pomocÄ… funkcji pakietu mice moÅ¼emy rÃ³wnieÅ¼ przedstawiÄ‡ graficznie gdzie i jak zostaÅ‚y uzupeÅ‚nione dane. densityplot(tempData, ~Ozone+Solar.R+Wind+Temp) stripplot(tempData, Ozone+Solar.R+Wind+Temp~.imp, pch = 20, cex = 1.2) Bibliografia "],
["podzia-metod-data-mining.html", "3 PodziaÅ‚ metod data mining 3.1 Rodzaje wnioskowania 3.2 Modele regresyjne 3.3 Modele klasyfikacyjne 3.4 Modele grupujÄ…ce", " 3 PodziaÅ‚ metod data mining 3.1 Rodzaje wnioskowania Data mining to zestaw metod pozyskiwania wiedzy na podstawie danych. OwÄ… wiedzÄ™ zdobywamy w procesie wnioskowania na podstawie modeli. Wnioskowanie moÅ¼emy podzieliÄ‡ na dedukcyjne i indukcyjne. I tak z wnioskowaniem dedukcyjnym mamy do czynienia wÃ³wczas, gdy na podstawie obecnego stanu wiedzy potrafimy odpowiedzieÄ‡ na postawione pytanie dotyczÄ…ce nowej wiedzy, stosujÄ…c reguÅ‚y wnioskowania. O wnioskowaniem indukcyjnym powiemy, Å¼e jest to metoda pozyskiwania wiedzy na podstawie informacji ze zbioru uczÄ…cego. Znajduje ono szerokie zastosowanie w data mining i charakteryzuje siÄ™ omylnoÅ›ciÄ…, poniewaÅ¼ nawet najlepiej nauczony model na zbiorze uczÄ…cym nie zapewnia nam prawdziwoÅ›ci odpowiedzi w przypadku nowych danych, a jedynie je uprawdopodabnia. EsencjÄ… wnioskowania indukcyjnego w zakresie data mining, jest poszukiwanie na podstawie danych uczÄ…cych modelu charakteryzujÄ…cego siÄ™ najlepszymi wÅ‚aÅ›ciwoÅ›ciami predykcyjnymi i dajÄ…cego siÄ™ zastosowaÄ‡ do zupeÅ‚nie nowego zbioru danych. KaÅ¼dy proces uczenia z wykorzystaniem wnioskowania indukcyjnego skÅ‚ada siÄ™ z nastÄ™pujÄ…cych elementÃ³w. 3.1.1 Dziedzina Dziedzina to zbiÃ³r wszystkich obiektÃ³w pozostajÄ…cych w zainteresowaniu badacza, bÄ™dÄ…cych przedmiotem wnioskowania, oznaczana najczÄ™Å›ciej przez \\(X\\). PrzykÅ‚adowo mogÄ… to byÄ‡ zbiory osÃ³b, transakcji, urzÄ…dzeÅ„, instytucji, itp. 3.1.2 Obserwacja KaÅ¼dy element dziedziny \\(x\\in X\\) nazywamy obserwacjÄ…. ObserwacjÄ… nazywaÄ‡ bÄ™dziemy zarÃ³wno rekordy danych ze zbioru uczÄ…cego, jak i ze zbioru testowego. 3.1.3 Atrybuty obserwacji KaÅ¼dy obiekt z dziedziny \\(x\\in X\\) moÅ¼na opisaÄ‡ zestawem cech (atrybutÃ³w), ktÃ³re w notacji matematycznej oznaczymy przez \\(a:X\\to A\\), gdzie \\(A\\) jest przestrzeniÄ… wartoÅ›ci atrybutÃ³w. KaÅ¼da obserwacja \\(x\\) posiadajÄ…ca \\(k\\) cech da siÄ™ wyraziÄ‡ wektorowo jako \\((a_1(x), a_2(x), \\ldots, a_k(x))\\). Dla wiÄ™kszoÅ›ci algorytmÃ³w uczenia maszynowego wyrÃ³Å¼nia siÄ™ trzy typy atrybutÃ³w: - nominalne - posiadajÄ…ce skoÅ„czonÄ… liczbÄ™ stanÃ³w, ktÃ³re posiadajÄ… porzÄ…dku; - porzÄ…dkowe - posiadajÄ…ce skoÅ„czonÄ… liczbÄ™ stanÃ³w z zachowaniem porzÄ…dku; - ciÄ…gÅ‚e - przyjmujÄ…ce wartoÅ›ci numeryczne. CzÄ™sto jeden z atrybutÃ³w speÅ‚nia specjalnÄ… rolÄ™, poniewaÅ¼ stanowi realizacjÄ™ cechy, ktÃ³rÄ… traktujemy jako wyjÅ›ciowÄ… (ang. target value attribute). W tym przypadku powiemy o nadzorowanym uczeniu maszynowym. JeÅ›li zmiennej wyjÅ›ciowej nie ma dziedzinie, to mÃ³wimy o nienadzorowanym uczeniu maszynowym. 3.1.4 ZbiÃ³r uczÄ…cy Zbiorem uczÄ…cym \\(T\\) (ang. training set) nazywamy podzbiÃ³r \\(D\\) dziedziny \\(X\\) (czyli \\(T\\subseteq D\\subseteq X\\)), gdzie zbiÃ³r \\(D\\) stanowi ogÃ³Å‚ dostÄ™pnych obserwacji z dziedziny \\(X\\). ZbiÃ³r uczÄ…cy zawiera informacje dotyczÄ…ce badanego zjawiska, na podstawie ktÃ³rych, dokonuje siÄ™ doboru modelu, selekcji cech istotnych z punktu widzenia wÅ‚asnoÅ›ci predykcyjnych lub jakoÅ›ci klasyfikacji, budowy modelu oraz optymalizacji jego parametrÃ³w. W przypadku uczenia z nauczycielem (nadzorowanego) zbiÃ³r \\(T\\) zawiera informacjÄ™ o wartoÅ›ciach atrybutÃ³w zmiennej wynikowej. 3.1.5 ZbiÃ³r testowy ZbiÃ³r testowy \\(T&#39;\\) (ang. test set) bÄ™dÄ…cy dopeÅ‚nieniem zbioru uczÄ…cego do zbioru \\(D\\), czyli \\(T&#39;=D\\setminus T\\), stanowi zestaw danych sÅ‚uÅ¼Ä…cy do oceny poprawnoÅ›ci modelu nadzorowanego. W przypadku metod nienadzorowanych raczej nie stosuje siÄ™ zbiorÃ³w testowych. 3.1.6 Model Model to narzÄ™dzie pozyskiwania wiedzy na podstawie zbioru uczÄ…cego. Nauczony model jest zbiorem reguÅ‚ \\(f\\), ktÃ³rego zadaniem jest oszacowanie wielkoÅ›ci wartoÅ›ci wynikowej lub odpowiednia klasyfikacja obiektÃ³w. W zadaniu grupowania obiektÃ³w (ang. clustering task), celem modelu jest podanie grup moÅ¼liwie najbardziej jednorodnych przy zadanym zestawie zmiennych oraz ustalonej liczbie skupieÅ„ (czasami wyznaczenie liczby skupieÅ„ jest rÃ³wnieÅ¼ czÄ™Å›ciÄ… zadania stawianego przed modelem). 3.1.7 JakoÅ›Ä‡ dopasowania modelu Do oceny jakoÅ›ci dopasowania modelu wykorzystuje siÄ™, w zaleÅ¼noÅ›ci od zadania, wiele wspÃ³Å‚czynnikÃ³w (np. dla zadaÅ„ regresyjnych sÄ… to bÅ‚Ä…d Å›rednio-kwadratowy - ang. Mean Square Error a dla zadaÅ„ klasyfikacyjnych - trafnoÅ›Ä‡ - ang. Accuracy). MoÅ¼emy mÃ³wiÄ‡ dwÃ³ch rodzajach dopasowania modeli: poziom dopasowania na zbiorze uczÄ…cym poziom dopasowania na zbiorze testowym (oczywiÅ›cie z punktu widzenia utylitarnoÅ›ci modelu ten wspÃ³Å‚czynnik jest waÅ¼niejszy). W sytuacji, w ktÃ³rej model wykazuje dobre charakterystyki jakoÅ›ci dopasowania na zbiorze uczÄ…cym ale sÅ‚abe na testowym, mÃ³wimy o zjawisku przeuczenia modelu (ang. overfitting). Oznacza to, Å¼e model wskazuje predykcjÄ™ poprawnie jedynie dla zbioru treningowego ale ma sÅ‚aba wÅ‚asnoÅ›ci generalizacyjne nowe przypadki danych. Takie model nie przedstawiajÄ… znaczÄ…cej wartoÅ›ci w odkrywaniu wiedzy w sposÃ³b indukcyjny. Z drugiej strony parametry dopasowania modelu mogÄ… pokazywaÄ‡ sÅ‚abe dopasowanie, zarÃ³wno na zbiorze uczÄ…cym, jak i testowym. WÃ³wczas rÃ³wnieÅ¼ model nie jest uÅ¼yteczny w pozyskiwaniu wiedzy na temat badanego zjawiska, a sytuacjÄ™ takÄ… nazywamy niedouczeniem (ang. underfitting). Figure 3.1: PrzykÅ‚ady niedoucznia (wykresy 1 i 4), poprawego modelu (2 i 5) i przeuczenia (3 i 6). Pierwszy wiersz wykresÃ³w pokazuje klasyfikacjÄ™ na podstawie modelu na zbiorze uczÄ…cym, a drugi na zbiorze testowym. Wykres na dole pokazuje zwiÄ…zek pomiÄ™dzy zÅ‚oÅ¼onoÅ›ciÄ… modelu a wielkoÅ›ciÄ… bÅ‚Ä™du predykcji. Å¹rÃ³dÅ‚o: https://cambridgecoding.wordpress.com/2016/03/24/misleading-modelling-overfitting-cross-validation-and-the-bias-variance-trade-off/ 3.2 Modele regresyjne Jednym z rodzajÃ³w zadaÅ„ bazujÄ…cym na wnioskowaniu indukcyjnym jest model regresyjny. NaleÅ¼y on do grupy metod nadzorowanych, ktÃ³rych celem jest oszacowanie wartoÅ›ci cechy wyjÅ›ciowej (ktÃ³ra jest iloÅ›ciowa) na podstawie zestawu predyktorÃ³w, ktÃ³re mogÄ… byÄ‡ iloÅ›ciowe i jakoÅ›ciowe. Uczenie takich modeli odbywa siÄ™ poprzez optymalizacjÄ™ funkcji celu (np. \\(MSE\\)) na podstawie zbioru uczÄ…cego. 3.3 Modele klasyfikacyjne Podobnie jak modele regresyjne, modele klasyfikacyjne naleÅ¼Ä… do grupy metod nadzorowanego uczenia maszynowego. Ich zadaniem jest wÅ‚aÅ›ciwa klasyfikacja obiektÃ³w na podstawie wielkoÅ›ci predyktorÃ³w. OdpowiedziÄ… modelu jest zawsze cecha typu jakoÅ›ciowego, natomiast predyktory mogÄ… mieÄ‡ dowolny typ. WyrÃ³Å¼nia siÄ™ klasyfikacjÄ™ dwu i wielostanowÄ…. Lista modeli realizujÄ…cych klasyfikacjÄ™ binarnÄ… jest nieco dÅ‚uÅ¼sza niÅ¼ w przypadku modeli z wielostanowÄ… cechÄ… wynikowÄ…. Proces uczenia modelu klasyfikacyjnego rÃ³wnieÅ¼ opiera siÄ™ na optymalizacji funkcji celu. Tym razem sÄ… to zupeÅ‚nie inne miary jakoÅ›ci dopasowania (np. trafnoÅ›Ä‡, czyli odsetek poprawnych klasyfikacji). 3.4 Modele grupujÄ…ce Bardzo szerokÄ… gamÄ™ modeli nienadzorowanych stanowiÄ… metody analizy skupieÅ„. Ich zadaniem jest grupowanie obiektÃ³w w moÅ¼liwie najbardziej jednorodne grupy, na podstawie wartoÅ›ci atrybutÃ³w poddanych analizie. PoniewaÅ¼ sÄ… to metody â€œbez nauczycielaâ€, to ocena ich przydatnoÅ›ci ma nieco inny charakter i choÄ‡ istniejÄ… rÃ³Å¼ne wskaÅºniki jakoÅ›ci grupowania, to trudno tu o obiektywne wskazanie najlepszego rozwiÄ…zania. "],
["drzewa-decyzyjne.html", "4 Drzewa decyzyjne 4.1 WÄ™zÅ‚y i gaÅ‚Ä™zie 4.2 Rodzaje reguÅ‚ podziaÅ‚u 4.3 Algorytm budowy drzewa 4.4 Kryteria zatrzymania 4.5 ReguÅ‚y podziaÅ‚u 4.6 Przycinanie drzewa decyzyjnego 4.7 ObsÅ‚uga brakÃ³w danych 4.8 Zalety i wady 4.9 PrzykÅ‚ad", " 4 Drzewa decyzyjne Drzewo decyzyjne13 jest strukturÄ… hierarchicznÄ… przedstawiajÄ…cÄ… model klasyfikacyjny lub regresyjny. Stosowane sÄ… szczegÃ³lnie czÄ™sto wÃ³wczas, gdy funkcyjna postaÄ‡ zwiÄ…zku pomiÄ™dzy predyktorami a zmiennÄ… wynikowÄ… jest nieznana lub ciÄ™Å¼ka do ustalenia. KaÅ¼de drzewo decyzyjne skÅ‚ada siÄ™ z korzenia (ang. root), wÄ™zÅ‚Ã³w (ang. nodes) i liÅ›ci (ang. leaves). Korzeniem nazywamy poczÄ…tkowy wÄ™zeÅ‚ drzewa, z ktÃ³rego poprzez podziaÅ‚y (ang. splits) powstajÄ… kolejne wÄ™zÅ‚y potomne. KoÅ„cowe wÄ™zÅ‚y, ktÃ³re nie podlegajÄ… podziaÅ‚om nazywamy liÅ›Ä‡mi, a linie Å‚Ä…czÄ…ce wÄ™zÅ‚y nazywamy gaÅ‚Ä™ziami (ang. branches). JeÅ›li drzewo sÅ‚uÅ¼y do zadaÅ„ klasyfikacyjnych, to liÅ›cie zawierajÄ… informacjÄ™ o tym, ktÃ³ra klasa w danym ciÄ…gu podziaÅ‚Ã³w jest najbardziej prawdopodobna. Natomiast jeÅ›li drzewo jest regresyjne, to liÅ›cie zawierajÄ… warunkowe miary tendencji centralnej (najczÄ™Å›ciej Å›redniÄ…) wartoÅ›ci zmiennej wynikowej. Warunek stanowi szereg podziaÅ‚Ã³w doprowadzajÄ…cy do danego wÄ™zÅ‚a terminalnego (liÅ›cia). W obu przypadkach (klasyfikacji i regresji) drzewo â€œdÄ…Å¼yâ€ do takiego podziaÅ‚u by kolejne wÄ™zÅ‚y, a co za tym idzie rÃ³wnieÅ¼ liÅ›cie, byÅ‚y ja najbardziej jednorodne ze wzglÄ™du na zmiennÄ… wynikowÄ…. Figure 4.1: PrzykÅ‚ad dziaÅ‚ania drzewa regresyjnego. Wykes w lewym gÃ³rnym rogu pokazuje prawdziwÄ… zaleÅ¼noÅ›Ä‡, wyres po prawej stronie jest ilustracjÄ… drzewa decyzyjnego, a wykres w lewym dolnym rogu pokazuje dyskretyzacjÄ™ przestrzeni dokonanÄ… przez drzewo, a za razem sposÃ³b jego dziaÅ‚ania. 4.1 WÄ™zÅ‚y i gaÅ‚Ä™zie KaÅ¼dy podziaÅ‚ rozdziela dziedzinÄ™ \\(X\\) na dwa lub wiÄ™cej podobszarÃ³w dziedziny i wÃ³wczas kaÅ¼da obserwacja wÄ™zÅ‚a nadrzÄ™dnego jest przyporzÄ…dkowana wÄ™zÅ‚om potomnym. KaÅ¼dy odchodzÄ…cy wÄ™zeÅ‚ potomny jest poÅ‚Ä…czony gaÅ‚Ä™ziÄ…, ktÃ³ra to wiÄ…Å¼e siÄ™ Å›ciÅ›le z moÅ¼liwymi wynikami podziaÅ‚u. KaÅ¼dy \\(\\mathbf{n}\\)-ty wÄ™zeÅ‚ moÅ¼na opisaÄ‡ jako podzbiÃ³r dziedziny w nastÄ™pujÄ…cy sposÃ³b \\[\\begin{equation} X_{\\mathbf{n}}=\\{x\\in X|t_1(x)=r_1,t_2(x)=r_2,\\ldots,t_k(x)=r_k\\}, \\end{equation}\\] gdzie \\(t_1,t_2,\\ldots,t_k\\) sÄ… podziaÅ‚ami, ktÃ³re przeprowadzajÄ… \\(x\\) w obszary \\(r_1, r_2,\\ldots, r_k\\). Przez \\[\\begin{equation} S_{\\mathbf{n}, t=r}=\\{x\\in S|t(x)=r\\} \\end{equation}\\] rozumiemy, Å¼e dokonano takiego ciÄ…gu podziaÅ‚Ã³w zbioru \\(S\\), Å¼e jego wartoÅ›ci znalazÅ‚y siÄ™ w \\(\\mathbf{n}\\)-tym wÄ™Åºle. 4.2 Rodzaje reguÅ‚ podziaÅ‚u NajczÄ™Å›ciej wystÄ™pujÄ…ce reguÅ‚y podziaÅ‚u w drzewach decyzyjnych sÄ… jednowymiarowe, czyli warunek podziaÅ‚u jest generowany na podstawie jednego atrybutu. IstniejÄ… podziaÅ‚y wielowymiarowe ale ze wzglÄ™du na zÅ‚oÅ¼onoÅ›Ä‡ obliczeniowÄ… sÄ… rzadziej stosowane. 4.2.1 PodziaÅ‚y dla atrybutÃ³w ze skali nominalnej IstniejÄ… dwa typy reguÅ‚ podziaÅ‚u dla skali nominalnej: oparte na wartoÅ›ci atrybutu (ang. value based) - wÃ³wczas funkcja testowa przyjmuje postaÄ‡ \\(t(x)=a(x)\\), czyli podziaÅ‚ generujÄ… wartoÅ›ci atrybutu; oparte na rÃ³wnoÅ›ci (ang. equality based) - gdzie funkcja testowa jest zdefiniowana jako \\[\\begin{equation} t(x)= \\begin{cases} 1, &amp;\\text{ gdy } a(x)=\\nu\\\\ 0, &amp; \\text{ w przeciwnym przypadku}, \\end{cases} \\end{equation}\\] gdzie \\(\\nu\\in A\\) i \\(A\\) jest zbiorem moÅ¼liwych wartoÅ›ci \\(a\\). W tym przypadku podziaÅ‚ jest dychotomiczny, albo obiekt ma wartoÅ›Ä‡ atrybutu rÃ³wnÄ… \\(\\nu\\), albo go nie ma. 4.2.2 PodziaÅ‚y dla atrybutÃ³w ze skali ciÄ…gÅ‚ej ReguÅ‚y podziaÅ‚u stosowane do skali ciÄ…gÅ‚ej, to: oparta na nierÃ³wnoÅ›ciach (ang. inequality based) - zdefiniowana jako \\[\\begin{equation} t(x) = \\begin{cases} 1, &amp;\\text{ gdy }a(x)\\leq \\nu\\\\ 0, &amp; \\text{w przeciwnym przypadku} \\end{cases} \\end{equation}\\] gdzie \\(\\nu\\in A\\); przedziaÅ‚owa (ang. interval based) - zdefiniowana jako \\[\\begin{equation} t(x) = \\begin{cases} 1, &amp;\\text{ gdy }a(x) \\in I_1\\\\ 2, &amp;\\text{ gdy }a(x) \\in I_2\\\\ \\vdots &amp; \\\\ k, &amp;\\text{ gdy }a(x) \\in I_k\\\\ \\end{cases} \\end{equation}\\] gdzie \\(I_1,I_2,\\ldots,I_k\\subset A\\) stanowiÄ… rozÅ‚Ä…czny podziaÅ‚ (przedziaÅ‚ami) przeciwdziedziny \\(A\\). 4.2.3 PodziaÅ‚y dla atrybutÃ³w ze skali porzÄ…dkowej PodziaÅ‚y te mogÄ… wykorzystywaÄ‡ oba wczeÅ›niej wspomniane typy, w zaleÅ¼noÅ›ci od potrzeb. 4.3 Algorytm budowy drzewa stwÃ³rz poczÄ…tkowy wÄ™zeÅ‚ (korzeÅ„) i oznacz go jako otwarty; przypisz wszystkie moÅ¼liwe rekordy do wÄ™zÅ‚a poczÄ…tkowego; dopÃ³ki istniejÄ… otwarte wÄ™zÅ‚y wykonuj: wybierz wÄ™zeÅ‚ \\(\\mathbf{n}\\), wyznacz potrzebne statystyki opisowe zmiennej zaleÅ¼nej dla tego wÄ™zÅ‚a i przypisz wartoÅ›Ä‡ docelowÄ…; jeÅ›li kryterium zatrzymania podziaÅ‚u jest speÅ‚nione dla wÄ™zÅ‚a \\(n\\), to oznacz go za zamkniÄ™ty; w przeciwnym przypadku wybierz podziaÅ‚ \\(r\\) elementÃ³w wÄ™zÅ‚a \\(\\mathbf{n}\\), i dla kaÅ¼dego podzbioru podziaÅ‚u stwÃ³rz wÄ™zeÅ‚ niÅ¼szego rzÄ™du (potomka) \\(\\mathbf{n}_r\\) oraz oznacz go jako otwarty; nastÄ™pnie przypisz wszystkie przypadki generowane podziaÅ‚em \\(r\\) do odpowiednich wÄ™zÅ‚Ã³w potomkÃ³w \\(\\mathbf{n}_r\\); oznacza wÄ™zeÅ‚ \\(\\mathbf{n}\\) jako zamkniÄ™ty. SposÃ³b przypisywania wartoÅ›ci docelowej wiÄ…Å¼e siÄ™ Å›ciÅ›le z rodzajem drzewa. W drzewach regresyjnych chodzi o wyliczenie Å›redniej lub mediany dla obserwacji ujÄ™tych w danym wÄ™Åºle. Natomiast w przypadku drzewa klasyfikacyjnego, wyznacza siÄ™ wartoÅ›ci prawdopodobieÅ„stw przynaleÅ¼noÅ›ci obserwacji znajdujÄ…cej siÄ™ w danym wÄ™Åºle do poszczegÃ³lnych klas \\[\\begin{equation} \\P(d|\\mathbf{n})=\\P(T_\\mathbf{n})(d)=\\frac{|T_\\mathbf{n}^d|}{|T_\\mathbf{n}|}, \\end{equation}\\] gdzie \\(T_\\mathbf{n}\\) oznaczajÄ… obserwacje zbioru uczÄ…cego znajdujÄ…ce siÄ™ w wÄ™Åºle \\(\\mathbf{n}\\), a \\(T_\\mathbf{n}^d\\) oznacza dodatkowo podzbiÃ³r zbioru uczÄ…cego w \\(\\mathbf{n}\\) wÄ™Åºle, ktÃ³re naleÅ¼Ä… do klasy \\(d\\). OczywiÅ›cie klasyfikacja na podstawie otrzymanych prawdopodobieÅ„stw w danym wÄ™Åºle jest dokonana przez wybÃ³r klasy charakteryzujÄ…cej siÄ™ najwyÅ¼szym prawdopodobieÅ„stwem. 4.4 Kryteria zatrzymania Kryterium zatrzymania jest warunkiem, ktÃ³ry decyduje o tym, Å¼e dany wÄ™zeÅ‚ uznajemy za zamkniÄ™ty i nie dokonujemy dalszego jego podziaÅ‚u. WyrÃ³Å¼niamy nastÄ™pujÄ…ce kryteria zatrzymania: jednorodnoÅ›Ä‡ wÄ™zÅ‚a - w przypadku drzewa klasyfikacyjnego moÅ¼e zdarzyÄ‡ siÄ™ sytuacja, Å¼e wszystkie obserwacje wÄ™zÅ‚a bÄ™dÄ… pochodziÅ‚y z jednej klasy. WÃ³wczas nie ma sensu dokonywaÄ‡ dalszego podziaÅ‚u wÄ™zÅ‚a; wÄ™zeÅ‚ jest pusty - zbiÃ³r przypisanych obserwacji zbioru uczÄ…cego do \\(\\mathbf{n}\\)-tego wÄ™zÅ‚a jest pusty; brak reguÅ‚ podziaÅ‚u - wszystkie reguÅ‚y podziaÅ‚u zostaÅ‚y wykorzystane, zatem nie da siÄ™ stworzyÄ‡ potomnych wÄ™zÅ‚Ã³w, ktÃ³re charakteryzowaÅ‚yby siÄ™ wiÄ™kszÄ… homogenicznoÅ›ciÄ…; Warunki ujÄ™te w pierwszych dwÃ³ch kryteriach mogÄ… byÄ‡ nieco zÅ‚agodzone, poprzez zatrzymanie podziaÅ‚Ã³w wÃ³wczas, gdy prawdopodobieÅ„stwo przynaleÅ¼enia do pewnej klasy przekroczy ustalony prÃ³g lub gdy liczebnoÅ›Ä‡ wÄ™zÅ‚a spadnie poniÅ¼ej ustalonej wartoÅ›ci. W literaturze tematu istnieje jeszcze jedno czÄ™sto stosowane kryterium zatrzymania oparte na wielkoÅ›ci drzewa. WÄ™zeÅ‚ potomny ustala siÄ™ jako zamkniÄ™ty, gdy dÅ‚ugoÅ›Ä‡ Å›cieÅ¼ki dojÅ›cia do nie go przekroczy ustalonÄ… wartoÅ›Ä‡. 4.5 ReguÅ‚y podziaÅ‚u WaÅ¼nym elementem algorytmu tworzenia drzewa regresyjnego jest reguÅ‚a podziaÅ‚u. Dobierana jest w taki sposÃ³b aby zmaksymalizowaÄ‡ zdolnoÅ›ci generalizacyjne drzewa. ZÅ‚oÅ¼onoÅ›Ä‡ drzewa mierzona jest najczÄ™Å›ciej przeciÄ™tnÄ… liczbÄ… podziaÅ‚Ã³w potrzebnych do dotarcia do liÅ›cia zaczynajÄ…c od korzenia. LiÅ›cie sÄ… najczÄ™Å›ciej tworzone wÃ³wczas gdy dyspersja wartoÅ›ci wynikowej jest stosunkowo maÅ‚a lub wÄ™zeÅ‚ zawiera w miarÄ™ homogeniczne obserwacje ze wzglÄ™du na przynaleÅ¼noÅ›Ä‡ do klasy zmiennej wynikowej. W przypadku drzew regresyjnych zmiennoÅ›Ä‡ na poziomie wÄ™zÅ‚Ã³w jest dobrÄ… miarÄ… sÅ‚uÅ¼Ä…cÄ… do definiowania podziaÅ‚u w wÄ™Åºle. I tak, jeÅ›li pewien podziaÅ‚ generuje nam stosunkowo maÅ‚e dyspersje wartoÅ›ci docelowych w wÄ™zÅ‚ach potomnych, to moÅ¼na ten podziaÅ‚ uznaÄ‡ za wÅ‚aÅ›ciwy. JeÅ›li \\(T_n\\) oznacza zbiÃ³r rekordÃ³w naleÅ¼Ä…cych do wÄ™zÅ‚a \\(n\\), a \\(T_{n,t=r}\\) sÄ… podzbiorami generowanymi przez podziaÅ‚ \\(r\\) w wÄ™zÅ‚ach potomnych dla \\(n\\), to dyspersjÄ™ wartoÅ›ci docelowej \\(f\\) bÄ™dziemy oznaczali nastÄ™pujÄ…co \\[\\begin{equation}\\label{dyspersja} \\operatorname{disp}_{T_{n,t=r}}(f). \\end{equation}\\] ReguÅ‚Ä™ podziaÅ‚u moÅ¼emy okreÅ›laÄ‡ poprzez minimalizacjÄ™ Å›redniej waÅ¼onej dyspersji wartoÅ›ci docelowej nastÄ™pujÄ…cej postaci \\[\\begin{equation}\\label{reg_podz} \\operatorname{disp}_n(f|t)=\\sum_{r\\in R_t}\\frac{|T_{n,t=r}|}{|T_n|}\\operatorname{disp}_{T_{n,t=r}}(f), \\end{equation}\\] gdzie \\(|\\ |\\) oznacza moc zbioru, a \\(R_t\\) zbiÃ³r wszystkich moÅ¼liwych wartoÅ›ci reguÅ‚y podziaÅ‚u. Czasami wygodniej bÄ™dzie maksymalizowaÄ‡ przyrost dyspersji (lub spadek) \\[\\begin{equation}\\label{przyrost} \\bigtriangleup \\operatorname{disp}_n(f|t)=\\operatorname{disp}_n(f)-\\sum_{r\\in R_t}\\frac{|T_{n,t=r}|}{|T_n|}\\operatorname{disp}_{T_{n,t=r}}(f). \\end{equation}\\] MiarÄ… heterogenicznoÅ›ci wÄ™zÅ‚Ã³w ze wzglÄ™du na zmiennÄ… wynikowÄ… (ang. impurity) w drzewach klasyfikacyjnych, ktÃ³ra pozwala na tworzenie kolejnych podziaÅ‚Ã³w wÄ™zÅ‚a, sÄ… najczÄ™Å›ciej wskaÅºnik Giniâ€™ego i entropia (Breiman et al. 2017). EntropiÄ… podzbioru uczÄ…cego w wÄ™Åºle \\(\\mathbf{n}\\), wyznaczamy wg wzoru \\[\\begin{equation} E_{T_{\\mathbf{n}}(c|t)} = \\sum_{x\\in R_t} \\frac{|T_{\\mathbf{n}, t=r}|}{|T_{\\mathbf{n}}|}E_{T_{\\mathbf{n}, t=r}}(c), \\end{equation}\\] gdzie \\(t\\) jest podziaÅ‚em (kandydatem), \\(r\\) potencjalnym wynikiem podziaÅ‚u \\(t\\), \\(c\\) jest oznaczeniem klasy zmiennej wynikowej, a \\[\\begin{equation} E_{T_{\\mathbf{n}, t=r}}(c) = \\sum_{d\\in C}-\\P_{T_{\\mathbf{n}, t=r}}(c=d)\\log\\P_{T_{\\mathbf{n}, t=r}}(c=d), \\end{equation}\\] przy czym \\[\\begin{equation} \\P_{T_{\\mathbf{n}, t=r}}(c=d)= \\P_{T_{\\mathbf{n}}}(c=d|t=r). \\end{equation}\\] Podobnie definiuje siÄ™ indeks Giniâ€™ego \\[\\begin{equation} Gi_{T_{\\mathbf{n}}(c|t)} = \\sum_{x\\in R_t} \\frac{|T_{\\mathbf{n}, t=r}|}{|T_{\\mathbf{n}}|}Gi_{T_{\\mathbf{n}, t=r}}(c), \\end{equation}\\] gdzie \\[\\begin{equation} Gi_{T_{\\mathbf{n}, t=r}}(c) = \\sum_{d\\in C}\\P_{T_{\\mathbf{n}, t=r}}(c=d)\\cdot(1-\\P_{T_{\\mathbf{n}, t=r}}(c=d))= 1-\\sum_{d\\in C}\\P^2_{T_{\\mathbf{n}, t=r}}(c=d). \\end{equation}\\] Dla tak zdefiniowanych miar â€œnieczystoÅ›ciâ€ wÄ™zÅ‚Ã³w, podziaÅ‚u dokonujemy w taki sposÃ³b, aby zminimalizowaÄ‡ wspÃ³Å‚czynnik Giniâ€™ego lub entropiÄ™. Im niÅ¼sze miary nieczystoÅ›ci, tym bardziej obserwacje znajdujÄ…ce siÄ™ w wÄ™Åºle sÄ… monokulturÄ…14. Nierzadko korzysta siÄ™ rÃ³wnieÅ¼ z wspÃ³Å‚czynnika przyrostu informacji (ang. information gain) \\[\\begin{equation} \\Delta E_{T_{\\mathbf{n}, t=r}}(c|t)=E_{T_{\\mathbf{n}, t=r}}(c)-E_{T_{\\mathbf{n}, t=r}}(c|t). \\end{equation}\\] Istnieje rÃ³wnieÅ¼ jego odpowiednik dla indeksu Giniâ€™ego. W obu przypadkach optymalnego podziaÅ‚u szukamy poprzez maksymalizacjÄ™ przyrostu informacji. 4.6 Przycinanie drzewa decyzyjnego Uczenie drzewa decyzyjnego wiÄ…Å¼e siÄ™ z ryzykiem przeuczenia modelu (podobnie jak to siÄ™ ma w przypadku innych modeli predykcyjnych). WczeÅ›niej przytoczone reguÅ‚y zatrzymania (np. gÅ‚Ä™bokoÅ›Ä‡ drzewa czy zatrzymanie przy osiÄ…gniÄ™ciu jednorodnoÅ›ci na zadanym poziomie) pomagajÄ… kontrolowaÄ‡ poziom generalizacji drzewa ale czasami bÄ™dzie dodatkowo potrzebne przyciÄ™cie drzewa, czyli usuniÄ™cie pewnych podziaÅ‚Ã³w, a co za tym idzie, rÃ³wnieÅ¼ liÅ›ci (wÄ™zÅ‚Ã³w). 4.6.1 Przycinanie redukujÄ…ce bÅ‚Ä…d JednÄ… ze strategii przycinania drzewa jest przycinanie redukujÄ…ce bÅ‚Ä…d (ang. reduced error pruning). Polega ono na porÃ³wnaniu bÅ‚Ä™dÃ³w (najczÄ™Å›ciej uÅ¼ywana jest miara odsetka bÅ‚Ä™dnych klasyfikacji lub MSE) liÅ›cia \\(\\mathbf{l}\\) i wÄ™zÅ‚a do ktÃ³rego drzewo przycinamy \\(\\mathbf{n}\\) na caÅ‚kiem nowym zbiorze uczÄ…cym \\(R\\). Niech \\(e_R(\\mathbf{l})\\) i \\(e_R(\\mathbf{n})\\) oznaczajÄ… odpowiednio bÅ‚Ä™dy na zbiorze \\(R\\) liÅ›cia i wÄ™zÅ‚a. WÃ³wczas jeÅ›li zachodzi warunek \\[\\begin{equation} e_R(\\mathbf{l})\\leq e_R(\\mathbf{n}), \\end{equation}\\] to zaleca siÄ™ zastÄ…piÄ‡ wÄ™zeÅ‚ \\(\\mathbf{n}\\) liÅ›ciem \\(\\mathbf{l}\\), czyli uczyniÄ‡ wÄ™zeÅ‚ \\(\\mathbf{n}\\) wÄ™zÅ‚em terminalnym. 4.6.2 Przycinanie minimalizujÄ…ce bÅ‚Ä…d Przycinanie minimalizujÄ…ce bÅ‚Ä…d opiera siÄ™ na spostrzeÅ¼eniu, Å¼e bÅ‚Ä…d drzewa przyciÄ™tego charakteryzuje siÄ™ zbyt pesymistycznÄ… ocenÄ… i dlatego wymaga korekty. WÄ™zeÅ‚ drzewa klasyfikacyjnego \\(\\mathbf{n}\\) zastÄ™pujemy liÅ›ciem \\(\\mathbf{l}\\), jeÅ›li \\[\\begin{equation} \\hat{e}_T(\\mathbf{l})\\leq \\hat{e}_T(\\mathbf{n}), \\end{equation}\\] gdzie \\[\\begin{equation} \\hat{e}_T(\\mathbf{n})=\\sum_{\\mathbf{n}&#39;\\in N(\\mathbf{n})}\\frac{|T_{\\mathbf{n}&#39;}|}{|T_\\mathbf{n}|}\\hat{e}_T(\\mathbf{n}&#39;), \\end{equation}\\] a \\(N(\\mathbf{n})\\) jest zbiorem wszystkich moÅ¼liwych wÄ™zÅ‚Ã³w potomnych wÄ™zÅ‚a \\(\\mathbf{n}\\) i \\[\\begin{equation} \\hat{e}_T(\\mathbf{l})=1-\\frac{|\\{x\\in T_\\mathbf{l}|c(x)=d_{\\mathbf{l}}\\}|+mp}{|T_\\mathbf{l}|+m}, \\end{equation}\\] gdzie \\(p\\) jest prawdopodobieÅ„stwem przynaleÅ¼noÅ›ci do klasy \\(d_{\\mathbf{l}}\\) ustalona na podstawie zewnÄ™trznej wiedzy (gdy jej nie posiadamy przyjmujemy \\(p=1/|C|\\)). W przypadku drzewa regresyjnego znajdujemy wiele analogii, poniewaÅ¼ jeÅ›li dla pewnego zbioru rekordÃ³w \\(T\\) speÅ‚niony jest warunek \\[\\begin{equation}\\label{kryterium1} \\operatorname{mse}_T(\\mathbf{l})\\leq\\operatorname{mse}_T(\\mathbf{n}), \\end{equation}\\] gdzie \\(\\mathbf{l}\\) i \\(\\mathbf{n}\\) oznaczajÄ… odpowiednio liÅ›Ä‡ i wÄ™zeÅ‚, to wÃ³wczas zastÄ™pujemy wÄ™zeÅ‚ \\(\\mathbf{n}\\) przez liÅ›Ä‡ \\(\\mathbf{l}\\). Estymatory wyznaczone na podstawie niewielkiej prÃ³by, mogÄ… byÄ‡ obarczone znaczÄ…cym bÅ‚Ä™dem. Wyliczanie bÅ‚Ä™du Å›rednio-kwadratowego dla podzbioru nowych wartoÅ›ci moÅ¼e siÄ™ charakteryzowaÄ‡ takim obciÄ…Å¼eniem. Dlatego stosuje siÄ™ statystyki opisowe z poprawkÄ…, ktÃ³rej pochodzenie moÅ¼e mieÄ‡ trzy ÅºrÃ³dÅ‚a: wiedza merytoryczna na temat szukanej wartoÅ›ci, zaÅ‚oÅ¼eÅ„ modelu lub na podstawie wyliczeÅ„ opartych o caÅ‚y zbiÃ³r wartoÅ›ci. Skorygowany estymator bÅ‚Ä™du Å›rednio-kwadratowego ma nastÄ™pujÄ…cÄ… postaÄ‡ \\[\\begin{equation}\\label{mse} \\widehat{\\operatorname{mse}}_T(\\mathbf{l})=\\frac{\\sum_{x\\in T}(f(x)-m_{\\mathbf{l},m,m_0}(f))^2+mS_0^2}{|T_\\mathbf{l}|+m}, \\end{equation}\\] gdzie \\[\\begin{equation}\\label{poprawka} m_{\\mathbf{l},m,m_0}(f)=\\frac{\\sum_{x\\in T_\\mathbf{l}}f(x)+mm_0}{|T_\\mathbf{l}|+m}, \\end{equation}\\] a \\(m_0\\) i \\(S_0^2\\) sÄ… Å›redniÄ… i wariancjÄ… wyznaczonymi na caÅ‚ej prÃ³bie uczÄ…cej. BÅ‚Ä…d Å›rednio-kwadratowy wÄ™zÅ‚a \\(\\mathbf{n}\\) ma postaÄ‡ \\[\\begin{equation}\\label{propagacja} \\widehat{\\operatorname{mse}}_T(\\mathbf{n})=\\sum_{\\mathbf{n}&#39;\\in N(\\mathbf{n})}\\frac{|T_{\\mathbf{n}&#39;}|}{|T_\\mathbf{n}|}\\widehat{\\operatorname{mse}}_T(\\mathbf{n}&#39;). \\end{equation}\\] WÃ³wczas kryterium podciÄ™cia moÅ¼na zapisaÄ‡ w nastÄ™pujÄ…cy sposÃ³b \\[\\begin{equation}\\label{kryterium2} \\widehat{\\operatorname{mse}}_T(\\mathbf{l}) \\leq \\widehat{\\operatorname{mse}}_T(\\mathbf{n}) \\end{equation}\\] 4.6.3 Przycinanie ze wzglÄ™du na wspÃ³Å‚czynnik zÅ‚oÅ¼onoÅ›ci drzewa Przycinanie ze wzglÄ™du na wspÃ³Å‚czynnik zÅ‚oÅ¼onoÅ›ci drzewa (ang. cost-complexity pruning) polega na wprowadzeniu â€œkaryâ€ za zwiÄ™kszonÄ… zÅ‚oÅ¼onoÅ›Ä‡ drzewa. Drzewa klasyfikacyjne przycinamy gdy speÅ‚niony jest warunek \\[\\begin{equation} e_T(\\mathbf{l})\\leq e_T(\\mathbf{n})+\\alpha C(\\mathbf{n}), \\end{equation}\\] gdzie \\(C(\\mathbf{n})\\) oznacza zÅ‚oÅ¼onoÅ›Ä‡ drzewa mierzonÄ… liczbÄ… liÅ›ci, a \\(\\alpha\\) parametrem wagi kary za zÅ‚oÅ¼onoÅ›Ä‡ drzewa. Wspomniane kryterium przyciÄ™cia dla drzew regresyjnych bazuje na wzglÄ™dnym bÅ‚Ä™dzie Å›rednio-kwadratowym (ang. relative square error), czyli \\[\\begin{equation}\\label{rse} \\widehat{\\operatorname{rse}}_T(\\mathbf{n})=\\frac{|T|\\widehat{\\operatorname{mse}}_T(\\mathbf{n})}{(|T|-1)S^2_T(f)}, \\end{equation}\\] gdzie \\(T\\) oznacza podzbiÃ³r \\(X\\), \\(S^2_T\\) wariancjÄ™ na zbiorze \\(T\\). WÃ³wczas kryterium podciÄ™cia wyglÄ…da nastÄ™pujÄ…co \\[\\begin{equation}\\label{kryterium3} \\widehat{\\operatorname{rse}}_T(\\mathbf{l})\\leq \\widehat{\\operatorname{rse}}_T(\\mathbf{n})+\\alpha C(\\mathbf{n}). \\end{equation}\\] 4.7 ObsÅ‚uga brakÃ³w danych Drzewa decyzyjne wyjÄ…tkowo dobrze radzÄ… sobie z obsÅ‚uga zbiorÃ³w z brakami. Stosowane sÄ… gÅ‚Ã³wnie dwie strategie: udziaÅ‚Ã³w obserwacji (ang. fractional instances) - rozwaÅ¼ane sÄ… wszystkie moÅ¼liwe podziaÅ‚y dla brakujÄ…cej obserwacji i przypisywana jest im odpowiednia waga lub prawdopodobieÅ„stwo, w oparciu o zaobserwowany rozkÅ‚ad znanych obserwacji. Te same wagi sÄ… stosowane do predykcji wartoÅ›ci na podstawie drzewa z brakami danych. podziaÅ‚Ã³w zastÄ™pczych (ang. surrogate splits) - jeÅ›li wynik podziaÅ‚u nie moÅ¼e byÄ‡ ustalony dla obserwacji z brakami, to uÅ¼ywany jest podziaÅ‚ zastÄ™pczy (pierwszy), jeÅ›li i ten nie moÅ¼e zostaÄ‡ ustalony, to stosuje siÄ™ kolejny. Kolejne podziaÅ‚y zastÄ™pcze sÄ… generowane tak, aby wynik podziaÅ‚u moÅ¼liwie najbardziej przypominaÅ‚ podziaÅ‚ wÅ‚aÅ›ciwy. 4.8 Zalety i wady 4.8.1 Zalety Å‚atwe w interpretacji; nie wymagajÄ… Å¼mudnego przygotowania danych (brak standaryzacji, wprowadzania zmiennych binarnych, dopuszcza wystÄ™powanie brakÃ³w danych); dziaÅ‚a na obu typach zmiennych - jakoÅ›ciowych i iloÅ›ciowych; dopuszcza nieliniowoÅ›Ä‡ zwiÄ…zku miÄ™dzy zmiennÄ… wynikowÄ… a predyktorami; odporny na odstÄ™pstwa od zaÅ‚oÅ¼eÅ„; pozwala na obsÅ‚ugÄ™ duÅ¼ych zbiorÃ³w danych. 4.8.2 Wady brak jawnej postaci zaleÅ¼noÅ›ci; zaleÅ¼noÅ›Ä‡ struktury drzewa od uÅ¼ytego algorytmu; przegrywa jakoÅ›ciÄ… predykcji z innymi metodami nadzorowanego uczenia maszynowego. 4.9 PrzykÅ‚ad PrzykÅ‚adem zastosowania drzew decyzyjnych bÄ™dzie klasyfikacja irysÃ³w na podstawie dÅ‚ugoÅ›ci i szerokoÅ›ci kielicha i pÅ‚atka. library(tidyverse) library(rpart) # pakiet do tworzenia drzew typu CART library(rpart.plot) # pakiet do rysowania drzew KaÅ¼de zadanie ucznia maszynowego zaczynamy od czyszczenia danych i odpowiedniego ich przygotowania ale w tym przypadku skupimy siÄ™ jedynie na budowie, optymalizacji i ewaluacji modelu. 4.9.1 PodziaÅ‚ zbioru na prÃ³bÄ™ uczÄ…cÄ… i testowÄ… set.seed(44) dt.train &lt;- iris %&gt;% sample_frac(size = 0.7) dt.test &lt;- setdiff(iris, dt.train) str(dt.train) ## &#39;data.frame&#39;: 105 obs. of 5 variables: ## $ Sepal.Length: num 6.4 4.4 6.6 5.4 5 5.4 5.6 4.4 5.4 6.1 ... ## $ Sepal.Width : num 2.7 3.2 3 3 3.6 3.4 2.9 2.9 3.9 2.9 ... ## $ Petal.Length: num 5.3 1.3 4.4 4.5 1.4 1.7 3.6 1.4 1.3 4.7 ... ## $ Petal.Width : num 1.9 0.2 1.4 1.5 0.2 0.2 1.3 0.2 0.4 1.4 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 3 1 2 2 1 1 2 1 1 2 ... str(dt.test) ## &#39;data.frame&#39;: 45 obs. of 5 variables: ## $ Sepal.Length: num 4.7 4.6 5.4 4.8 5.8 5.1 5.1 5.1 5 5.2 ... ## $ Sepal.Width : num 3.2 3.1 3.9 3.4 4 3.8 3.7 3.3 3 3.5 ... ## $ Petal.Length: num 1.3 1.5 1.7 1.6 1.2 1.5 1.5 1.7 1.6 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.4 0.2 0.2 0.3 0.4 0.5 0.2 0.2 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... 4.9.2 Budowa drzewa Budowy drzewa dokonujemy za pomocÄ… funkcji rpart pakietu rpart (Therneau and Atkinson 2018) stosujÄ…c zapis formuÅ‚y zaleÅ¼noÅ›ci. Drzewo zostanie zbudowane z uwzglÄ™dnieniem kilku kryteriÃ³w zatrzymania: minimalna liczebnoÅ›Ä‡ wÄ™zÅ‚a, ktÃ³ry moÅ¼e zostaÄ‡ podzielony to 10 - ze wzglÄ™du na maÅ‚Ä… liczebnoÅ›Ä‡ zbioru uczÄ…cego; minimalna liczebnoÅ›Ä‡ liÅ›cia to 5 - aby nie dopuÅ›ciÄ‡ do przeuczenia modelu; maksymalna gÅ‚Ä™bokoÅ›Ä‡ drzewa to 4 - aby nie dopuÅ›ciÄ‡ do przeuczenia modelu. mod.rpart &lt;- rpart(Species~., data = dt.train, control = rpart.control(minsplit = 10, minbucket = 5, maxdepth = 4)) summary(mod.rpart) ## Call: ## rpart(formula = Species ~ ., data = dt.train, control = rpart.control(minsplit = 10, ## minbucket = 5, maxdepth = 4)) ## n= 105 ## ## CP nsplit rel error xerror xstd ## 1 0.51470588 0 1.00000000 1.1764706 0.06418173 ## 2 0.41176471 1 0.48529412 0.6617647 0.07457243 ## 3 0.02941176 2 0.07352941 0.1029412 0.03758880 ## 4 0.01000000 3 0.04411765 0.1029412 0.03758880 ## ## Variable importance ## Petal.Width Petal.Length Sepal.Length Sepal.Width ## 35 33 21 12 ## ## Node number 1: 105 observations, complexity param=0.5147059 ## predicted class=setosa expected loss=0.647619 P(node) =1 ## class counts: 37 33 35 ## probabilities: 0.352 0.314 0.333 ## left son=2 (37 obs) right son=3 (68 obs) ## Primary splits: ## Petal.Length &lt; 2.45 to the left, improve=35.95322, (0 missing) ## Petal.Width &lt; 0.8 to the left, improve=35.95322, (0 missing) ## Sepal.Length &lt; 5.45 to the left, improve=25.39467, (0 missing) ## Sepal.Width &lt; 3.35 to the right, improve=12.69596, (0 missing) ## Surrogate splits: ## Petal.Width &lt; 0.8 to the left, agree=1.000, adj=1.000, (0 split) ## Sepal.Length &lt; 5.45 to the left, agree=0.924, adj=0.784, (0 split) ## Sepal.Width &lt; 3.35 to the right, agree=0.819, adj=0.486, (0 split) ## ## Node number 2: 37 observations ## predicted class=setosa expected loss=0 P(node) =0.352381 ## class counts: 37 0 0 ## probabilities: 1.000 0.000 0.000 ## ## Node number 3: 68 observations, complexity param=0.4117647 ## predicted class=virginica expected loss=0.4852941 P(node) =0.647619 ## class counts: 0 33 35 ## probabilities: 0.000 0.485 0.515 ## left son=6 (38 obs) right son=7 (30 obs) ## Primary splits: ## Petal.Width &lt; 1.75 to the left, improve=25.286380, (0 missing) ## Petal.Length &lt; 4.75 to the left, improve=24.879360, (0 missing) ## Sepal.Length &lt; 5.75 to the left, improve= 6.713875, (0 missing) ## Sepal.Width &lt; 3.25 to the left, improve= 1.336180, (0 missing) ## Surrogate splits: ## Petal.Length &lt; 4.75 to the left, agree=0.882, adj=0.733, (0 split) ## Sepal.Length &lt; 6.15 to the left, agree=0.721, adj=0.367, (0 split) ## Sepal.Width &lt; 3.15 to the left, agree=0.618, adj=0.133, (0 split) ## ## Node number 6: 38 observations, complexity param=0.02941176 ## predicted class=versicolor expected loss=0.1315789 P(node) =0.3619048 ## class counts: 0 33 5 ## probabilities: 0.000 0.868 0.132 ## left son=12 (32 obs) right son=13 (6 obs) ## Primary splits: ## Petal.Length &lt; 4.95 to the left, improve=4.0800440, (0 missing) ## Petal.Width &lt; 1.45 to the left, improve=1.2257490, (0 missing) ## Sepal.Width &lt; 2.65 to the right, improve=0.6168705, (0 missing) ## Sepal.Length &lt; 5.95 to the left, improve=0.4736842, (0 missing) ## Surrogate splits: ## Petal.Width &lt; 1.55 to the left, agree=0.868, adj=0.167, (0 split) ## ## Node number 7: 30 observations ## predicted class=virginica expected loss=0 P(node) =0.2857143 ## class counts: 0 0 30 ## probabilities: 0.000 0.000 1.000 ## ## Node number 12: 32 observations ## predicted class=versicolor expected loss=0.03125 P(node) =0.3047619 ## class counts: 0 31 1 ## probabilities: 0.000 0.969 0.031 ## ## Node number 13: 6 observations ## predicted class=virginica expected loss=0.3333333 P(node) =0.05714286 ## class counts: 0 2 4 ## probabilities: 0.000 0.333 0.667 rpart.plot(mod.rpart) Figure 4.2: Obraz drzewa klasyfikacyjnego. PowyÅ¼szy wykres przedstawia strukturÄ™ drzewa klasyfikacyjnego. Kolorami sÄ… oznaczone klasy, ktÃ³re w danym wÄ™Åºle dominujÄ…. Nasycenie barwy decyduje o sile tej dominacji. W kaÅ¼dym wÄ™Åºle podana jest klasa, do ktÃ³rej najprawdopodobniej naleÅ¼Ä… jego obserwacje. Ponadto podane sÄ… proporcje przynaleÅ¼noÅ›ci do klas zmiennej wynikowej oraz procent obserwacji zbioru uczÄ…cego naleÅ¼Ä…cych do danego wÄ™zÅ‚a. Pod kaÅ¼dym wÄ™zÅ‚em podana jest reguÅ‚a podziaÅ‚u. 4.9.3 Przycinanie drzewa Zanim przystÄ…pimy do przycinania drzewa naleÅ¼y sprawdziÄ‡, jakie sÄ… zdolnoÅ›ci generalizacyjne modelu. Oceny tej dokonujemy najczÄ™Å›ciej sprawdzajÄ…c macierz klasyfikacji. pred.prob &lt;- predict(mod.rpart, newdata = dt.test) pred.prob[10:20,] ## setosa versicolor virginica ## 10 1 0.00000 0.00000 ## 11 1 0.00000 0.00000 ## 12 1 0.00000 0.00000 ## 13 1 0.00000 0.00000 ## 14 0 0.96875 0.03125 ## 15 0 0.96875 0.03125 ## 16 0 0.96875 0.03125 ## 17 0 0.96875 0.03125 ## 18 0 0.96875 0.03125 ## 19 0 0.96875 0.03125 ## 20 0 0.00000 1.00000 pred.class &lt;- predict(mod.rpart, newdata = dt.test, type = &quot;class&quot;) pred.class ## 1 2 3 4 5 6 ## setosa setosa setosa setosa setosa setosa ## 7 8 9 10 11 12 ## setosa setosa setosa setosa setosa setosa ## 13 14 15 16 17 18 ## setosa versicolor versicolor versicolor versicolor versicolor ## 19 20 21 22 23 24 ## versicolor virginica versicolor versicolor versicolor versicolor ## 25 26 27 28 29 30 ## versicolor versicolor versicolor versicolor versicolor versicolor ## 31 32 33 34 35 36 ## virginica virginica virginica virginica virginica virginica ## 37 38 39 40 41 42 ## virginica virginica virginica virginica virginica virginica ## 43 44 45 ## virginica virginica virginica ## Levels: setosa versicolor virginica tab &lt;- table(predykcja = pred.class, obserwacja = dt.test$Species) tab ## obserwacja ## predykcja setosa versicolor virginica ## setosa 13 0 0 ## versicolor 0 16 0 ## virginica 0 1 15 Jak widaÄ‡ z powyÅ¼szej tabeli, model caÅ‚kiem dobrze radzi sobie z poprawnÄ… klasyfikacjÄ… obserwacji do odpowiednich kategorii. Tylko jedna obserwacja zostaÅ‚a bÅ‚Ä™dnie zaklasyfikowana. W dalszej kolejnoÅ›ci sprawdzimy, czy nie jest konieczne przyciÄ™cie drzewa. Jednym z kryteriÃ³w przycinania drzewa jest przycinanie ze wzglÄ™du na zÅ‚oÅ¼onoÅ›Ä‡ drzewa. W tym przypadku jest wyraÅ¼ony parametrem cp. Istnieje powszechnie stosowana reguÅ‚a jednego odchylenia standardowego, ktÃ³ra mÃ³wi, Å¼e drzewo naleÅ¼y przyciÄ…Ä‡ wÃ³wczas, gdy bÅ‚Ä…d oszacowany na podstawie sprawdzianu krzyÅ¼owego (xerror), pierwszy raz zejdzie poniÅ¼ej poziomu wyznaczonego przez najniÅ¼szÄ… wartoÅ›Ä‡ bÅ‚Ä™du powiÄ™kszonego o odchylenie standardowe tego bÅ‚Ä™du (xstd). Na podstawie poniÅ¼szej tabeli moÅ¼na ustaliÄ‡, Å¼e poziomem odciÄ™cia jest wartoÅ›Ä‡ \\(0.10294+0.037589=0.140529\\). Pierwszy raz bÅ‚Ä…d przyjmuje wartoÅ›Ä‡ mniejszÄ… od \\(0.140529\\) po drugim podziale (nsplit=2). Temu poziomowi odpowiada cp o wartoÅ›ci \\(0.029412\\) i to jest zÅ‚oÅ¼onoÅ›Ä‡ drzewa, ktÃ³rÄ… powinniÅ›my przyjÄ…Ä‡ do przyciÄ™cia drzewa. printcp(mod.rpart) ## ## Classification tree: ## rpart(formula = Species ~ ., data = dt.train, control = rpart.control(minsplit = 10, ## minbucket = 5, maxdepth = 4)) ## ## Variables actually used in tree construction: ## [1] Petal.Length Petal.Width ## ## Root node error: 68/105 = 0.64762 ## ## n= 105 ## ## CP nsplit rel error xerror xstd ## 1 0.514706 0 1.000000 1.17647 0.064182 ## 2 0.411765 1 0.485294 0.66176 0.074572 ## 3 0.029412 2 0.073529 0.10294 0.037589 ## 4 0.010000 3 0.044118 0.10294 0.037589 plotcp(mod.rpart) Figure 4.3: Na wykresie bÅ‚Ä™dÃ³w punkt odciÄ™cia zaznaczony jest liniÄ… przerywanÄ… PrzyciÄ™te drzewo wyglÄ…da nastÄ™pujÄ…co: mod.rpart2 &lt;- prune(mod.rpart, cp = 0.029412) summary(mod.rpart2) ## Call: ## rpart(formula = Species ~ ., data = dt.train, control = rpart.control(minsplit = 10, ## minbucket = 5, maxdepth = 4)) ## n= 105 ## ## CP nsplit rel error xerror xstd ## 1 0.5147059 0 1.00000000 1.1764706 0.06418173 ## 2 0.4117647 1 0.48529412 0.6617647 0.07457243 ## 3 0.0294120 2 0.07352941 0.1029412 0.03758880 ## ## Variable importance ## Petal.Width Petal.Length Sepal.Length Sepal.Width ## 35 31 22 12 ## ## Node number 1: 105 observations, complexity param=0.5147059 ## predicted class=setosa expected loss=0.647619 P(node) =1 ## class counts: 37 33 35 ## probabilities: 0.352 0.314 0.333 ## left son=2 (37 obs) right son=3 (68 obs) ## Primary splits: ## Petal.Length &lt; 2.45 to the left, improve=35.95322, (0 missing) ## Petal.Width &lt; 0.8 to the left, improve=35.95322, (0 missing) ## Sepal.Length &lt; 5.45 to the left, improve=25.39467, (0 missing) ## Sepal.Width &lt; 3.35 to the right, improve=12.69596, (0 missing) ## Surrogate splits: ## Petal.Width &lt; 0.8 to the left, agree=1.000, adj=1.000, (0 split) ## Sepal.Length &lt; 5.45 to the left, agree=0.924, adj=0.784, (0 split) ## Sepal.Width &lt; 3.35 to the right, agree=0.819, adj=0.486, (0 split) ## ## Node number 2: 37 observations ## predicted class=setosa expected loss=0 P(node) =0.352381 ## class counts: 37 0 0 ## probabilities: 1.000 0.000 0.000 ## ## Node number 3: 68 observations, complexity param=0.4117647 ## predicted class=virginica expected loss=0.4852941 P(node) =0.647619 ## class counts: 0 33 35 ## probabilities: 0.000 0.485 0.515 ## left son=6 (38 obs) right son=7 (30 obs) ## Primary splits: ## Petal.Width &lt; 1.75 to the left, improve=25.286380, (0 missing) ## Petal.Length &lt; 4.75 to the left, improve=24.879360, (0 missing) ## Sepal.Length &lt; 5.75 to the left, improve= 6.713875, (0 missing) ## Sepal.Width &lt; 3.25 to the left, improve= 1.336180, (0 missing) ## Surrogate splits: ## Petal.Length &lt; 4.75 to the left, agree=0.882, adj=0.733, (0 split) ## Sepal.Length &lt; 6.15 to the left, agree=0.721, adj=0.367, (0 split) ## Sepal.Width &lt; 3.15 to the left, agree=0.618, adj=0.133, (0 split) ## ## Node number 6: 38 observations ## predicted class=versicolor expected loss=0.1315789 P(node) =0.3619048 ## class counts: 0 33 5 ## probabilities: 0.000 0.868 0.132 ## ## Node number 7: 30 observations ## predicted class=virginica expected loss=0 P(node) =0.2857143 ## class counts: 0 0 30 ## probabilities: 0.000 0.000 1.000 rpart.plot(mod.rpart2) Figure 4.4: Drzewo klasyfikacyjne po przyciÄ™ciu 4.9.4 Ocena dopasowania modelu Na koniec budowy modelu naleÅ¼y sprawdziÄ‡ jego jakoÅ›Ä‡ na zbiorze testowym. pred.class2 &lt;- predict(mod.rpart2, newdata = dt.test, type = &quot;class&quot;) tab2 &lt;- table(predykcja = pred.class2, obserwacja = dt.test$Species) tab2 ## obserwacja ## predykcja setosa versicolor virginica ## setosa 13 0 0 ## versicolor 0 16 0 ## virginica 0 1 15 Mimo przyciÄ™cia drzewa, klasyfikacja pozostaje na niezmienionym poziomie. Odsetek poprawnych klasyfikacji moÅ¼emy oszacowaÄ‡ za pomocÄ… round(sum(diag(tab2))/sum(tab2)*100,1) ## [1] 97.8 Bibliografia "],
["bibliografia.html", "Bibliografia", " Bibliografia "]
]
